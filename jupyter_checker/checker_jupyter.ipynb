{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c2d4bd-2c89-45fa-b369-ff29bc842232",
   "metadata": {},
   "source": [
    "# MASTERDATA CHECKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235db9ca-3a9b-475d-9b92-4e8e52895959",
   "metadata": {},
   "source": [
    "##### GUIDE:\n",
    "\n",
    "Just execute all the cells, on by one, and do what it says: Select instance, introduce user and password and click on login, etc.\n",
    "\n",
    "Execute all the methods in the section \"FUNCTIONS\" and run the checker and visualizer at the end of the notebook to see how it works. (For the checker, you need to upload a file, just an upload button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5afeb3-dfc4-4186-b7b7-d1d7f0a71549",
   "metadata": {},
   "source": [
    "## LOGIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1410b8-e416-4f4f-8c81-bc16d03234df",
   "metadata": {},
   "source": [
    "Here just execute this cell to import all the needed classes and packages tht this tool includes. If some of the import fails, try to execute \"pip install\" + package_name (name of the package that failed, for example, pip install ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2ae08e-ea6a-4d91-8858-4edbb3bf4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pybis import Openbis\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7270de7-d7f8-4aa5-98e2-132411ad2d55",
   "metadata": {},
   "source": [
    "### Select the instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ed2a2-d049-4d9f-aba4-c21dd7a49b8f",
   "metadata": {},
   "source": [
    "After executing the following cell (you don't need to change anything, just run it), a dropdown selector will appear, where you will need just to select the desired openbis instance, and continue to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3317a7f8-a7b4-42e5-987e-68b38eedc868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb236df195945e3944dbcab1f9b5e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Instance:', options=('devel', 'main', 'schulung', 'test'), value='devel')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instance = widgets.Dropdown(\n",
    "    options=['devel', 'main', 'schulung', 'test'],\n",
    "    value='devel',\n",
    "    description='Instance:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601fe13-f7da-42a7-b35f-4c9cab6e5cee",
   "metadata": {},
   "source": [
    "### Enter username and password to login into selected openBIS instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067b3cf-6cd7-4bff-9919-af365ab55eda",
   "metadata": {},
   "source": [
    "Same as before, just execute the following cell without touching the code, and a login widget will appear, where you will need to introduce your username and password, and then click in the \"Login\" button. If something fails, you can use the cell after this one to login in a dfferent way. If it works, \"Login succesful!\" will appear under the button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba19e23-a94a-4cd8-8da4-d9c5d1c924b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aba37d8a37444fb4499894f04e7cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='User:', placeholder='Enter user name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8b91b5ac34407d88f3b42290776d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Password(description='Password:', placeholder='Enter password')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb50f629aa8a48a794eb370f5ef743ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Login', icon='login', style=ButtonStyle(), tooltip='Click to login…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47e6e32bdc4ec0a17bd556d63cca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usr = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter user name',\n",
    "    description='User:',\n",
    "    disabled=False   \n",
    ")\n",
    "psswd = widgets.Password(\n",
    "    value='',\n",
    "    placeholder='Enter password',\n",
    "    description='Password:',\n",
    "    disabled=False\n",
    ")\n",
    "output = widgets.Output()\n",
    "url = f\"https://{instance.value}.datastore.bam.de/\"\n",
    "o = Openbis(url)\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()  # Clear previous output\n",
    "        username = usr.value\n",
    "        password = psswd.value\n",
    "        o.login(username, password, save_token=True)\n",
    "        if(o.is_session_active()):\n",
    "            display(HTML(f\"<p>Login successful!</p>\"))\n",
    "        else:\n",
    "            display(HTML(f\"<p>Login failed: {str(e)}</p>\"))\n",
    "\n",
    "button = widgets.Button(\n",
    "    description=\"Login\",\n",
    "    button_style='success', \n",
    "    tooltip='Click to login in openBIS',\n",
    "    icon='login' \n",
    ")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "display(usr)\n",
    "display(psswd)\n",
    "display(button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6d2f2-e359-4696-b4c7-63280c75338f",
   "metadata": {},
   "source": [
    "Just execute this cell if the above login code fails! Not needed if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4868fbd5-95cd-43f9-95e6-5d520ca4fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmadaria-240920110401198xF4A4EE07B906EA51A4EB2DA73AFDB831'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = usr.value\n",
    "password = psswd.value\n",
    "\n",
    "url = f\"https://{instance.value}.datastore.bam.de/\"\n",
    "o = Openbis(url)\n",
    "o.login(username, password, save_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b038ff8-7e81-4f13-9dc5-e7d5fa8efb12",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc85ec-37ac-481c-8936-89ba4a15b2da",
   "metadata": {},
   "source": [
    "Here are the needed functions to execute the masterdata checker and visualizer. Execute all of them. It won't produce any output and the execution will be instant, imagine this as \"registering\" the functions. We will execute them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35cad684-a6a4-4116-bb54-20a708afbf65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def name_checker(file_path):\n",
    "    file_name = file_path.split(\"\\\\\")[-1]\n",
    "    \n",
    "    # Define the pattern for a valid file name\n",
    "    pattern = r\"^(collection_type|object_type|dataset_type|vocabulary)_([\\w.]+)_(v\\d+)_([a-zA-Z0-9]+(?:\\.[0-9]+)?)_([a-zA-Z0-9]+)\\.(xls|xlsx)$\"\n",
    " \n",
    "    # Check if the file name matches the pattern\n",
    "    match = re.match(pattern, file_name)\n",
    "\n",
    "    if match:\n",
    "        # Extract parts of the file name\n",
    "        entity_type, entity_name, version, division, contact_person, extension = match.groups()\n",
    "        #print(entity_type, entity_name, version, division, contact_person, extension)\n",
    "        return [\"File name: OK!\", True]\n",
    "    else:\n",
    "        # Return specific errors and positions\n",
    "        errors = []\n",
    "        file_name = file_name.split(\".xls\")\n",
    "        \n",
    "        if len(file_name) < 2:\n",
    "            raise UserFailureException(\"Error: Invalid file type. The file should be an Excel file (.xls or .xlsx)\")\n",
    "        \n",
    "        else:\n",
    "            file_parts = file_name[0].split(\"_\")\n",
    "            if len(file_parts) < 5:\n",
    "                errors.append(\"Invalid name format. The name should contain different fields separated by underscores (_). Consult the wiki to see the right format.\")\n",
    "                return [\"\\n\".join(errors), False]\n",
    "            creator = file_parts.pop(-1)\n",
    "            section = file_parts.pop(-1)\n",
    "            version = file_parts.pop(-1)\n",
    "            etype = file_parts.pop(0)\n",
    "            if (etype == \"object\" or etype == \"collection\" or etype == \"dataset\"):\n",
    "                etype = etype + \"_\" + file_parts.pop(0)\n",
    "            code = \"_\".join(file_parts)\n",
    "            \n",
    "            if not re.match(r\"^(collection_type|object_type|dataset_type|vocabulary)$\", etype):\n",
    "                errors.append(\"Invalid entity type at position 1.\")\n",
    "            if not re.match(r\"^([\\w.]+)$\", code):\n",
    "                errors.append(\"Invalid entity name at position 2.\")\n",
    "            if not re.match(r\"^(v\\d+)$\", version):\n",
    "                errors.append(\"Invalid version at position 3.\")\n",
    "            if not re.match(r\"^([a-zA-Z0-9]+(?:\\.[0-9]+)?)$\", section):\n",
    "                errors.append(\"Invalid division at position 4.\")\n",
    "            if not re.match(r\"^[a-zA-Z0-9]+$\", creator):\n",
    "                errors.append(\"Invalid contact person at position 5.\")\n",
    "            \n",
    "            return [\"\\n\".join(errors), False]\n",
    "\n",
    "class UserFailureException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6ad617c-c264-4f09-a806-e6ac9f849686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_excel_column(index):\n",
    "    column = ''\n",
    "    while index > 0:\n",
    "        index, remainder = divmod(index - 1, 26)\n",
    "        column = chr(65 + remainder) + column\n",
    "    return column\n",
    "\n",
    "\n",
    "def check_properties(sheet, errors):\n",
    "    expected_terms = [\n",
    "        \"Version\",\n",
    "        \"Code\",\n",
    "        \"Description\",\n",
    "        \"Mandatory\",\n",
    "        \"Show in edit views\",\n",
    "        \"Section\",\n",
    "        \"Property label\",\n",
    "        \"Data type\",\n",
    "        \"Vocabulary code\"\n",
    "    ]\n",
    "    row_headers = [cell.value for cell in sheet[4]]\n",
    "    for term in expected_terms:\n",
    "        if (term not in row_headers):\n",
    "            if term in (\"Mandatory\",\"Show in edit views\",\"Section\"):\n",
    "                errors.append(f\"Warning: '{term}' not found in the properties headers.\")\n",
    "            else:\n",
    "                errors.append(f\"Error: '{term}' not found in the properties headers.\")\n",
    "        else:\n",
    "             # Find the index of the term in the second row\n",
    "             term_index = row_headers.index(term) + 1\n",
    "             term_letter = index_to_excel_column(term_index)\n",
    "             #print(term_index)\n",
    "             \n",
    "             # Check the column below \"Version\"\n",
    "             if term == \"Version\":\n",
    "                 column_below_version = []\n",
    "                 for cell in sheet[term_letter][4:]:\n",
    "                     if cell.value is not None:\n",
    "                         column_below_version.append(cell.value)\n",
    "                     else:\n",
    "                         pass\n",
    "\n",
    "                 # Check if any value in the column is not an integer\n",
    "                 non_integer_indices = [i + 5 for i, cell in enumerate(column_below_version) if not (str(cell).isnumeric() or \"$\" in str(cell))]\n",
    "                 if non_integer_indices:\n",
    "                     # Append an error indicating the positions (row numbers) that are not integers\n",
    "                     errors.append(f\"Error: Values not valid found in the 'Version' column (they should be Integers) at row(s): {', '.join(map(str, non_integer_indices))}\")\n",
    "\n",
    "            # Check the column below \"Code\"\n",
    "             elif term == \"Code\":\n",
    "                column_below_code = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_code.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_codes = [i + 5 for i, cell in enumerate(column_below_code) if not (re.match(r'^\\$?[A-Z0-9_.]+$', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_codes:\n",
    "                    # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                    errors.append(f\"Error: Invalid code found in the '{term}' column at row(s): {', '.join(map(str, invalid_codes))}\")\n",
    "                    \n",
    "                #check that all the properties of the object are different using a set (unique terms):\n",
    "                if len(set(column_below_code)) != len(column_below_code):\n",
    "                    seen_props = set()\n",
    "                    repeated_props = set()\n",
    "                    for prop in column_below_code:\n",
    "                        if prop in seen_props:\n",
    "                            repeated_props.add(prop)\n",
    "                        else:\n",
    "                            seen_props.add(prop)\n",
    "                    errors.append(f\"Error: The following properties are repeated: {repeated_props}. Please, delete the duplicates, and leave just one occurence\")\n",
    "\n",
    "            \n",
    "            \n",
    "            # Check the cell below \"Description\"\n",
    "             elif term == \"Description\":\n",
    "                column_below_description = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_description.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_indices = [i + 5 for i, cell in enumerate(column_below_description) if not (re.match(r'.*//.*', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_indices:\n",
    "                    errors.append(f\"Error: Invalid value(s) found in the '{term}' column at row(s): {', '.join(map(str, invalid_indices))}. Description should follow the schema: English Description + '//' + German Description.\")\n",
    "\n",
    "            # Check the cell below \"Mandatory\"\n",
    "             elif term == \"Mandatory\":\n",
    "                column_below_mandatory = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_mandatory.append(str(cell.value).upper())\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_mandatory = [i + 5 for i, cell in enumerate(column_below_mandatory) if (cell not in [\"TRUE\", \"FALSE\"] and \"$\" not in str(cell))]\n",
    "                if invalid_mandatory:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_mandatory))}. Accepted values: TRUE, FALSE\")\n",
    "\n",
    "            # Check the cell below \"Show in edit views\"\n",
    "             elif term == \"Show in edit views\":\n",
    "                column_below_show = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_show.append(str(cell.value).upper())\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_show = [i + 5 for i, cell in enumerate(column_below_show) if (cell not in [\"TRUE\", \"FALSE\"] and \"$\" not in str(cell))]\n",
    "                if invalid_show:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_show))}. Accepted values: TRUE, FALSE\")\n",
    "\n",
    "            # Check the cell below \"Section\"\n",
    "             elif term == \"Section\":\n",
    "                column_below_section = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_section.append(cell.value) if '$' not in cell.value else column_below_section.append(cell.value.replace('$', ''))\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_section = [i + 5 for i, cell in enumerate(column_below_section) if not (re.match(r'^[A-Z][A-Za-z]*(?:\\s[A-Z][A-Za-z]*)*$', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_section:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_section))}. Each word in the Section should start with a capital letter.\")\n",
    "\n",
    "                # Group Check: Ensure all properties within the same section are grouped together\n",
    "                seen_sections = {}\n",
    "                non_contiguous_rows = []\n",
    "                \n",
    "                for i, current_value in enumerate(column_below_section):\n",
    "                    if current_value in seen_sections:\n",
    "                        # If the value has been seen before but the row is not contiguous, add an error\n",
    "                        if seen_sections[current_value] != i - 1:\n",
    "                            non_contiguous_rows.append(i + 5)\n",
    "                    seen_sections[current_value] = i  # Update the last seen row index for the current value\n",
    "                \n",
    "                if non_contiguous_rows:\n",
    "                    errors.append(f\"Error: Non-contiguous rows found for the same 'Section' value at row(s): {', '.join(map(str, non_contiguous_rows))}. Ensure that all properties within the same Section are grouped together.\")\n",
    "            \n",
    "                # Predefined section order (fixed order)\n",
    "                predefined_section_order = [\"General Information\", \"Additional Information\", \"Comments\"]\n",
    "            \n",
    "                # Validate contiguous groups and predefined section order\n",
    "                seen_sections = set()\n",
    "                previous_section_type = None\n",
    "                section_errors = []  # Store section-specific errors\n",
    "                additional_info_seen = False  # Flag to track if \"Additional Information\" has been seen\n",
    "                comments_seen = False  # Flag to track if \"Comments\" has been seen\n",
    "            \n",
    "                # Traverse the section list\n",
    "                for i, section in enumerate(column_below_section):\n",
    "                    if section in predefined_section_order:\n",
    "                        if section == \"General Information\":\n",
    "                            if previous_section_type not in [None, \"General Information\"]:\n",
    "                                section_errors.append(f\"Error at row {i + 5}: Section 'General Information' should only appear at the beginning.\")\n",
    "                        elif section == \"Additional Information\":\n",
    "                            if previous_section_type not in [\"General Information\", \"user-defined\"]:\n",
    "                                section_errors.append(f\"Error at row {i + 5}: Section 'Additional Information' should appear after 'General Information' and any user-defined sections.\")\n",
    "                            additional_info_seen = True  # Mark that \"Additional Information\" has been encountered\n",
    "                        elif section == \"Comments\":\n",
    "                            if previous_section_type not in [\"General Information\", \"user-defined\", \"Additional Information\"]:\n",
    "                                section_errors.append(f\"Error at row {i + 5}: Section 'Comments' should appear after 'Additional Information'.\")\n",
    "                            comments_seen = True  # Mark that \"Comments\" has been encountered\n",
    "                        previous_section_type = section\n",
    "                    else:\n",
    "                        # User-defined section\n",
    "                        if comments_seen:\n",
    "                            section_errors.append(f\"Error at row {i + 5}: User-defined section '{section}' cannot appear after 'Comments'.\")\n",
    "                        if additional_info_seen and not comments_seen:\n",
    "                            section_errors.append(f\"Error at row {i + 5}: User-defined section '{section}' cannot appear after 'Additional Information' but before 'Comments'.\")\n",
    "                        previous_section_type = \"user-defined\"\n",
    "            \n",
    "                # Output any errors\n",
    "                if section_errors:\n",
    "                    for error in section_errors:\n",
    "                        errors.append(error)\n",
    "                        \n",
    "            # Check the cell below \"Property label\"\n",
    "             elif term == \"Property label\":\n",
    "                column_below_label = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_label.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_label = [i + 5 for i, cell in enumerate(column_below_label) if not (re.match(r'.*', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_label:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_label))}. Specify the property label as text format\")\n",
    "\n",
    "                # Dynamically find the \"Section\" column\n",
    "                if \"Section\" in row_headers:\n",
    "                    section_index = row_headers.index(\"Section\") + 1\n",
    "                    section_letter = index_to_excel_column(section_index)\n",
    "                    column_below_section = [cell.value for cell in sheet[section_letter][4:]]\n",
    "\n",
    "                    for i, label_value in enumerate(column_below_label):\n",
    "                        if label_value == \"Notes\":\n",
    "                            section_value = column_below_section[i]\n",
    "                            if section_value != \"Additional Information\":\n",
    "                                errors.append(f\"Error: 'Notes' found in the 'Property label' column at row {i + 5}, but corresponding 'Section' is not 'Additional Information'. Value found: {section_value}\")\n",
    "\n",
    "            # Check the cell below \"Data type\"\n",
    "             elif term == \"Data type\":\n",
    "                column_below_type = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_type.append(str(cell.value).upper())\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_type = [i + 5 for i, cell in enumerate(column_below_type) if (cell not in [\"INTEGER\", \"REAL\", \"VARCHAR\", \"MULTILINE_VARCHAR\", \"HYPERLINK\", \"BOOLEAN\", \"CONTROLLEDVOCABULARY\", \"XML\", \"TIMESTAMP\", \"DATE\", \"SAMPLE\"] and \"$\" not in str(cell))]\n",
    "                if invalid_type:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_type))}. Accepted types: INTEGER, REAL, VARCHAR, MULTILINE_VARCHAR, HYPERLINK, BOOLEAN, CONTROLLEDVOCABULARY, XML, TIMESTAMP, DATE, SAMPLE\")\n",
    "\n",
    "            # Check the column below \"Vocabulary code\"\n",
    "             elif term == \"Vocabulary code\":\n",
    "                column_below_vocab = sheet[term_letter][4:]\n",
    "                invalid_vocab = [i + 5 for i, cell in enumerate(column_below_vocab) if cell.value and not (re.match(r'^\\$?[A-Z0-9_.]', str(cell.value)) or \"$\" not in str(cell))]\n",
    "                if invalid_vocab:\n",
    "                    # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                    errors.append(f\"Error: Invalid vocabulary code found in the '{term}' column at row(s): {', '.join(map(str, invalid_vocab))}\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def check_vocab_terms(sheet, errors):\n",
    "    expected_terms = [\n",
    "        \"Version\",\n",
    "        \"Code\",\n",
    "        \"Label\"\n",
    "        \"Description\"\n",
    "    ]\n",
    "    row_headers = [cell.value for cell in sheet[4]]\n",
    "    for term in expected_terms:\n",
    "        if term not in row_headers:\n",
    "            errors.append(f\"Error: '{term}' not found in the vocabulary term headers.\")\n",
    "        else:\n",
    "             # Find the index of the term in the second row\n",
    "             term_index = row_headers.index(term) + 1\n",
    "             term_letter = index_to_excel_column(term_index)\n",
    "             #print(term_index)\n",
    "             \n",
    "             # Check the column below \"Version\"\n",
    "             if term == \"Version\":\n",
    "                 column_below_version = []\n",
    "                 for cell in sheet[term_letter][4:]:\n",
    "                     if cell.value is not None:\n",
    "                         column_below_version.append(cell.value)\n",
    "                     else:\n",
    "                         pass\n",
    "\n",
    "                 # Check if any value in the column is not an integer\n",
    "                 non_integer_indices = [i + 5 for i, cell in enumerate(column_below_version) if not str(cell).isnumeric()]\n",
    "                 if non_integer_indices:\n",
    "                     # Append an error indicating the positions (row numbers) that are not integers\n",
    "                     errors.append(f\"Error: Values not valid found in the 'Version' column (they should be Integers) at row(s): {', '.join(map(str, non_integer_indices))}\")\n",
    "\n",
    "            # Check the column below \"Code\"\n",
    "             elif term == \"Code\":\n",
    "                column_below_code = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_code.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_codes = [i + 5 for i, cell in enumerate(column_below_code) if not re.match(r'^\\$?[A-Z0-9_.]+$', str(cell))]\n",
    "                if invalid_codes:\n",
    "                    # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                    errors.append(f\"Error: Invalid code found in the '{term}' column at row(s): {', '.join(map(str, invalid_codes))}\")\n",
    "                \n",
    "                #check that all the properties of the object are different using a set (unique terms):\n",
    "                if len(set(column_below_code)) != len(column_below_code):\n",
    "                    seen_terms = set()\n",
    "                    repeated_terms = set()\n",
    "                    for term in column_below_code:\n",
    "                        if term in seen_terms:\n",
    "                            repeated_terms.add(term)\n",
    "                        else:\n",
    "                            seen_terms.add(term)\n",
    "                    errors.append(f\"Error: The following vocabulary terms are repeated: {repeated_terms}. Please, delete the duplicates, and leave just one occurence\")\n",
    "\n",
    "            \n",
    "            \n",
    "            # Check the cell below \"Description\"\n",
    "             elif term == \"Description\":\n",
    "                column_below_description = sheet[term_letter][4:]\n",
    "                invalid_description = [i + 5 for i, cell in enumerate(column_below_description) if cell.value and not re.match(r'.*//.*', str(cell.value))]\n",
    "                if invalid_description:\n",
    "                    errors.append(f\"Error: Invalid value(s) found in the '{term}' column at row(s): {', '.join(map(str, invalid_description))}. Description should follow the schema: English Description + '//' + German Description.\")\n",
    "\n",
    "            # Check the cell below \"Mandatory\"\n",
    "             elif term == \"Label\":\n",
    "                column_below_label = sheet[term_letter][4:]\n",
    "                invalid_label = [i + 5 for i, cell in enumerate(column_below_label) if cell.value and not re.match(r'.*', str(cell.value))]\n",
    "                if invalid_label:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_section))}. Specify the label as text format\")\n",
    "            \n",
    "    return \"\\n\".join(errors)\n",
    "\n",
    "#file_path = 'C:/Users/cmadaria/Documents/Projects/Type checker/object_type_CHEMICAL_v1_S.3_relathma.xlsx'\n",
    "def content_checker(file_path, name_ok):\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    errors = []\n",
    "\n",
    "    if(name_ok):\n",
    "        file_name = file_path.split(\"\\\\\")[-1]\n",
    "        file_name = file_name.split(\".xls\")\n",
    "        file_parts = file_name[0].split(\"_\")\n",
    "        file_parts.pop(-1)\n",
    "        file_parts.pop(-1)\n",
    "        version = file_parts.pop(-1)\n",
    "        etype = file_parts.pop(0)\n",
    "        if (etype == \"object\" or etype == \"collection\" or etype == \"dataset\"):\n",
    "            etype = etype + \"_\" + file_parts.pop(0)\n",
    "        code = \"_\".join(file_parts)\n",
    "    else:\n",
    "        version, etype, code = \"\", \"\", \"\"\n",
    "\n",
    "    sheet = workbook.active\n",
    "    \n",
    "    filtered_rows = []\n",
    "    \n",
    "    for row in sheet.iter_rows(min_row=1, values_only=True):\n",
    "    # Check if any cell in the row contains \"$\"\n",
    "        if any(\"$\" in str(cell) for cell in row):\n",
    "            filtered_rows.append([\"$\" + str(cell) if cell is not None else None for cell in row])\n",
    "        else:\n",
    "            # If the row passed the check, add it to the filtered list\n",
    "            filtered_rows.append(row)\n",
    "    \n",
    "    #remove all the rows in the sheet\n",
    "    sheet.delete_rows(0, sheet.max_row)\n",
    "\n",
    "    # Append the filtered rows to the sheet\n",
    "    for row_data in filtered_rows:\n",
    "        sheet.append(row_data)\n",
    "\n",
    "    # Access a specific cell (e.g., cell A1)\n",
    "    cell_value_A1 = sheet['A1'].value\n",
    "    print(f\"Entity Type: {cell_value_A1}\")\n",
    "    \n",
    "    entity_types = [\"SAMPLE_TYPE\", \"EXPERIMENT_TYPE\", \"DATASET_TYPE\", \"PROPERTY_TYPE\", \"VOCABULARY_TYPE\"]\n",
    "    if cell_value_A1 not in entity_types:\n",
    "        errors.append(\"The entity type (cell A1) should be one of the following: SAMPLE_TYPE, EXPERIMENT_TYPE, DATASET_TYPE, PROPERTY_TYPE, VOCABULARY_TYPE\")\n",
    "        return \"\\n\".join(errors)\n",
    "    else:\n",
    "        if cell_value_A1 == \"SAMPLE_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\",\n",
    "                \"Validation script\",\n",
    "                \"Generated code prefix\",\n",
    "                \"Auto generate codes\",\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the entity headers.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term)\n",
    "\n",
    "                     # Check the cell below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        cell_below_version = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if str(cell_below_version.value) != version[1:]:\n",
    "                            errors.append(\"Error: The version should be the same one indicated in the file name\")\n",
    "\n",
    "                    # Check the cell below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        cell_below_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if cell_below_code.value != code:\n",
    "                            errors.append(\"Error: The code should be the same one indicated in the file name\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        cell_below_description = sheet.cell(row=3, column=term_index + 1)\n",
    "                        description_pattern = re.compile(r\".*//.*\")\n",
    "                        if not description_pattern.match(cell_below_description.value):\n",
    "                            errors.append(\"Error: Description should follow the schema: English Description + '//' + German Description.\")\n",
    "\n",
    "                    # Check the cell below \"Generated code prefix\"\n",
    "                     elif term == \"Generated code prefix\":\n",
    "                        cell_below_generated_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        code_replace = code.replace('_', '.').split('.')\n",
    "                        ext_code = [word[:3].upper() for word in code_replace]\n",
    "                        generated_code = '.'.join(ext_code)\n",
    "                        if cell_below_generated_code.value != generated_code:\n",
    "                            errors.append(\"Warning: It is recommended that the value of 'Generated code prefix' be the first three letters of each part of the 'Code' separated by dots ['.'].\")\n",
    "\n",
    "                    # Check the cell below \"Validation script\"\n",
    "                     elif term == \"Validation script\":\n",
    "                        cell_below_validation = sheet.cell(row=3, column=term_index + 1)\n",
    "                        validation_pattern = re.compile(r\"^[A-Za-z0-9_]+\\.py$\")\n",
    "                        if cell_below_validation.value and not validation_pattern.match(cell_below_validation.value):\n",
    "                             errors.append(\"Error: Validation script should follow the schema: Words and/or numbers separated by '_' and ending in '.py'\")\n",
    "\n",
    "\n",
    "                    # Check the cell below \"Auto generate codes\"\n",
    "                     elif term == \"Auto generate codes\":\n",
    "                        cell_below_auto_generate = sheet.cell(row=3, column=term_index + 1)\n",
    "                        auto_code = cell_below_auto_generate.value\n",
    "                        if (auto_code == True): auto_code = \"TRUE\"\n",
    "                        if (auto_code == False): auto_code = \"FALSE\"\n",
    "                        if auto_code not in [\"TRUE\", \"FALSE\"]:\n",
    "                            errors.append(\"Error: Value below 'Auto generate codes' should be 'TRUE' or 'FALSE'.\")\n",
    "            \n",
    "            errors = check_properties(sheet, errors)      \n",
    "            \n",
    "        elif cell_value_A1 == \"EXPERIMENT_TYPE\" or cell_value_A1 == \"DATASET_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\",\n",
    "                \"Validation script\"\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the second row.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term)\n",
    "\n",
    "                     # Check the cell below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        cell_below_version = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if str(cell_below_version.value) != version[1:]:\n",
    "                            errors.append(\"Error: The version should be the same one indicated in the file name\")\n",
    "\n",
    "                    # Check the cell below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        cell_below_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if cell_below_code.value != code:\n",
    "                            errors.append(\"Error: The code should be the same one indicated in the file name\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        cell_below_description = sheet.cell(row=3, column=term_index + 1)\n",
    "                        description_pattern = re.compile(r\".*//.*\")\n",
    "                        if not description_pattern.match(cell_below_description.value):\n",
    "                            errors.append(\"Error: Description should follow the schema: English Description + '//' + German Description.\")\n",
    "            \n",
    "            \n",
    "                    # Check the cell below \"Validation script\"\n",
    "                     elif term == \"Validation script\":\n",
    "                        cell_below_validation = sheet.cell(row=3, column=term_index + 1)\n",
    "                        validation_pattern = re.compile(r\"^[A-Za-z0-9_]+\\.py$\")\n",
    "                        if cell_below_validation.value and not validation_pattern.match(cell_below_validation.value):\n",
    "                            errors.append(\"Error: Validation script should follow the schema: Words and/or numbers separated by '_' and ending in '.py'\")\n",
    "\n",
    "            errors = check_properties(sheet, errors) \n",
    "            \n",
    "        elif cell_value_A1 == \"VOCABULARY_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\"\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the second row.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term)\n",
    "\n",
    "                     # Check the cell below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        cell_below_version = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if str(cell_below_version.value) != version[1:]:\n",
    "                            errors.append(\"Error: The version should be the same one indicated in the file name. Value found: {cell_below_version.value}\")\n",
    "\n",
    "                    # Check the cell below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        cell_below_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if cell_below_code.value != code:\n",
    "                            errors.append(\"Error: The code should be the same one indicated in the file name. Value found: {cell_below_code.value}\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        cell_below_description = sheet.cell(row=3, column=term_index + 1)\n",
    "                        description_pattern = re.compile(r\".*//.*\")\n",
    "                        if not description_pattern.match(cell_below_description.value):\n",
    "                            errors.append(\"Error: Description should follow the schema: English Description + '//' + German Description. Value found: {cell_below_description.value}\")\n",
    "            \n",
    "            errors = check_vocab_terms(sheet, errors)\n",
    "\n",
    "        elif cell_value_A1 == \"PROPERTY_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\",\n",
    "                \"Mandatory\",\n",
    "                \"Show in edit views\",\n",
    "                \"Section\",\n",
    "                \"Property label\",\n",
    "                \"Data type\",\n",
    "                \"Vocabulary code\"\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the second row.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term) + 1\n",
    "\n",
    "\n",
    "                     # Check the column below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        column_below_version = sheet[term_index][2:]\n",
    "                        # Check if any value in the column is not an integer\n",
    "                        non_integer_cells = [(i + 3, cell.value) for i, cell in enumerate(column_below_version) if not isinstance(cell.value, int)]\n",
    "                        if non_integer_cells:\n",
    "                            # Append an error indicating the positions (row numbers) that are not integers\n",
    "                            non_integer_indices = [str(row) for row, _ in non_integer_cells]\n",
    "                            invalid_values = [str(value) for _, value in non_integer_cells]\n",
    "                            errors.append(f\"Error: Values not valid found in the 'Version' column (they should be Integers) at row(s): {', '.join(non_integer_indices)}. Value(s) found: {', '.join(invalid_values)}\")\n",
    "\n",
    "                    # Check the column below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        column_below_code = sheet[term_index][2:]\n",
    "                        invalid_codes = [(i + 3, cell.value) for i, cell in enumerate(column_below_code) if not re.match(r'^\\$?[A-Z0-9_.]+$', str(cell.value))]\n",
    "                        if invalid_codes:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_codes]\n",
    "                            invalid_values = [str(value) for _, value in invalid_codes]\n",
    "                            errors.append(f\"Error: Invalid code found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Value(s) found: {', '.join(invalid_values)}\")\n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        column_below_description = sheet[term_index][2:]\n",
    "                        invalid_descriptions = [(i + 3, cell.value) for i, cell in enumerate(column_below_description) if not re.match(r'.*//.*', str(cell.value))]\n",
    "                        if invalid_descriptions:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_descriptions]\n",
    "                            invalid_values = [str(value) for _, value in invalid_descriptions]\n",
    "                            errors.append(f\"Error: Invalid value(s) found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Description should follow the schema: English Description + '//' + German Description. Value(s) found: {', '.join(invalid_values)}\")\n",
    "                    \n",
    "                    # Check the cell below \"Mandatory\"\n",
    "                     elif term == \"Mandatory\":\n",
    "                        column_below_mandatory = sheet[term_index][2:]\n",
    "                        invalid_mandatory = [(i + 3, cell.value) for i, cell in enumerate(column_below_mandatory) if cell.value not in [\"TRUE\", \"FALSE\"]]\n",
    "                        if invalid_mandatory:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_mandatory]\n",
    "                            invalid_values = [str(value) for _, value in invalid_mandatory]\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Accepted values: TRUE, FALSE. Value(s) found: {', '.join(invalid_values)}\")\n",
    "                    \n",
    "                    # Check the cell below \"Show in edit views\"\n",
    "                     elif term == \"Show in edit views\":\n",
    "                        column_below_show = sheet[term_index][2:]\n",
    "                        invalid_show = [(i + 3, cell.value) for i, cell in enumerate(column_below_show) if cell.value not in [\"TRUE\", \"FALSE\"]]\n",
    "                        if invalid_show:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_show]\n",
    "                            invalid_values = [str(value) for _, value in invalid_show]\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Accepted values: TRUE, FALSE. Value(s) found: {', '.join(invalid_values)}\")\n",
    "                    \n",
    "                    # Check the cell below \"Section\"\n",
    "                     elif term == \"Section\":\n",
    "                        column_below_section = sheet[term_index][2:]\n",
    "                        invalid_section = [(i + 3, cell.value) for i, cell in enumerate(column_below_section) if not re.match(r'^[A-Z][A-Za-z]*(?:\\s[A-Z][A-Za-z]*)*$', str(cell.value))]\n",
    "                        if invalid_section:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_section]\n",
    "                            invalid_values = [str(value) for _, value in invalid_section]\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Specify the section as text format with each word starting with capital letter. Value(s) found: {', '.join(invalid_values)}\")\n",
    "\n",
    "                         # Group Check: Ensure all properties within the same section are grouped together\n",
    "                            seen_sections = {}\n",
    "                            non_contiguous_rows = []\n",
    "                            \n",
    "                            for i, current_value in enumerate(column_below_section):\n",
    "                                if current_value in seen_sections:\n",
    "                                    # If the value has been seen before but the row is not contiguous, add an error\n",
    "                                    if seen_sections[current_value] != i - 1:\n",
    "                                        non_contiguous_rows.append(i + 5)\n",
    "                                seen_sections[current_value] = i  # Update the last seen row index for the current value\n",
    "                            \n",
    "                            if non_contiguous_rows:\n",
    "                                errors.append(f\"Error: Non-contiguous rows found for the same 'Section' value at row(s): {', '.join(map(str, non_contiguous_rows))}. Ensure that all properties within the same Section are grouped together.\")\n",
    "                        \n",
    "                            # Predefined section order (fixed order)\n",
    "                            predefined_section_order = [\"General Information\", \"Additional Information\", \"Comments\"]\n",
    "                        \n",
    "                            # Validate contiguous groups and predefined section order\n",
    "                            current_section = None\n",
    "                            seen_sections = set()\n",
    "                            previous_section_type = None\n",
    "                            user_defined_started = False\n",
    "                            section_errors = []  # Store section-specific errors\n",
    "                            additional_info_seen = False  # Flag to track if \"Additional Information\" has been seen\n",
    "                            comments_seen = False  # Flag to track if \"Comments\" has been seen\n",
    "                        \n",
    "                            # Traverse the section list\n",
    "                            for i, section in enumerate(column_below_section):\n",
    "                                if section in predefined_section_order:\n",
    "                                    if section == \"General Information\":\n",
    "                                        if previous_section_type not in [None, \"General Information\"]:\n",
    "                                            section_errors.append(f\"Error at row {i + 5}: 'General Information' should only appear at the beginning.\")\n",
    "                                    elif section == \"Additional Information\":\n",
    "                                        if previous_section_type not in [\"General Information\", \"user-defined\"]:\n",
    "                                            section_errors.append(f\"Error at row {i + 5}: 'Additional Information' should appear after 'General Information' and any user-defined sections.\")\n",
    "                                        additional_info_seen = True  # Mark that \"Additional Information\" has been encountered\n",
    "                                    elif section == \"Comments\":\n",
    "                                        if previous_section_type not in [\"General Information\", \"user-defined\", \"Additional Information\"]:\n",
    "                                            section_errors.append(f\"Error at row {i + 5}: 'Comments' should appear after 'Additional Information'.\")\n",
    "                                        comments_seen = True  # Mark that \"Comments\" has been encountered\n",
    "                                    previous_section_type = section\n",
    "                                else:\n",
    "                                    # User-defined section\n",
    "                                    if comments_seen:\n",
    "                                        section_errors.append(f\"Error at row {i + 5}: User-defined section '{section}' cannot appear after 'Comments'.\")\n",
    "                                    if additional_info_seen and not comments_seen:\n",
    "                                        section_errors.append(f\"Error at row {i + 5}: User-defined section '{section}' cannot appear after 'Additional Information' but before 'Comments'.\")\n",
    "                                    previous_section_type = \"user-defined\"\n",
    "                        \n",
    "                            # Output any errors\n",
    "                            if section_errors:\n",
    "                                for error in section_errors:\n",
    "                                    errors.append(error)\n",
    "                                    \n",
    "                    # Check the cell below \"Property label\"\n",
    "                     elif term == \"Property label\":\n",
    "                        column_below_label = sheet[term_index][2:]\n",
    "                        invalid_label = [(i + 3, cell.value) for i, cell in enumerate(column_below_label) if not re.match(r'.*', str(cell.value))]\n",
    "                        if invalid_label:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_label]\n",
    "                            invalid_values = [str(value) for _, value in invalid_label]\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Specify the property label as text format. Value(s) found: {', '.join(invalid_values)}\")\n",
    "                         # Dynamically find the \"Section\" column\n",
    "                        if \"Section\" in row_headers:\n",
    "                            section_column_index = row_headers.index(\"Section\") + 1  # Find the index of the \"Section\" column\n",
    "                            section_letter = index_to_excel_column(section_column_index)  # Convert index to Excel column letter\n",
    "                            column_below_section = sheet[section_letter][2:]  # Get all cells below the \"Section\" header\n",
    "\n",
    "                            # New check for \"Notes\" in \"Property label\" and \"Additional Information\" in \"Section\"\n",
    "                            for i, cell in enumerate(column_below_label):\n",
    "                                if cell.value == \"Notes\":\n",
    "                                    section_value = column_below_section[i].value  # Get the value in the \"Section\" column for the same row\n",
    "                                    if section_value != \"Additional Information\":\n",
    "                                        errors.append(f\"Error: 'Notes' found in the 'Property label' column at row {i + 5}, but corresponding 'Section' column does not contain 'Additional Information'. Value found: {section_value}\")\n",
    "                    \n",
    "                    # Check the cell below \"Data type\"\n",
    "                     elif term == \"Data type\":\n",
    "                        column_below_type = sheet[term_index][2:]\n",
    "                        invalid_type = [(i + 3, cell.value) for i, cell in enumerate(column_below_type) if cell.value not in [\"INTEGER\", \"REAL\", \"VARCHAR\", \"MULTILINE_VARCHAR\", \"HYPERLINK\", \"BOOLEAN\", \"CONTROLLEDVOCABULARY\", \"XML\", \"TIMESTAMP\", \"DATE\", \"SAMPLE\"]]\n",
    "                        if invalid_type:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_type]\n",
    "                            invalid_values = [str(value) for _, value in invalid_type]\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Accepted types: INTEGER, REAL, VARCHAR, MULTILINE_VARCHAR, HYPERLINK, BOOLEAN, CONTROLLEDVOCABULARY, XML, TIMESTAMP, DATE, SAMPLE. Value(s) found: {', '.join(invalid_values)}\")\n",
    "                    \n",
    "                    # Check the column below \"Vocabulary code\"\n",
    "                     elif term == \"Vocabulary code\":\n",
    "                        column_below_vocab = sheet[term_index][2:]\n",
    "                        invalid_vocab = [(i + 3, cell.value) for i, cell in enumerate(column_below_vocab) if cell.value is not None and not re.match(r'^\\$?[A-Z0-9_.]+$', str(cell.value))]\n",
    "                        if invalid_vocab:\n",
    "                            invalid_rows = [str(row) for row, _ in invalid_vocab]\n",
    "                            invalid_values = [str(value) for _, value in invalid_vocab]\n",
    "                            errors.append(f\"Error: Invalid vocabulary code found in the '{term}' column at row(s): {', '.join(invalid_rows)}. Value(s) found: {', '.join(invalid_values)}\")\n",
    "\n",
    "    # Close the workbook after use\n",
    "    workbook.close()\n",
    "    output = \"\\n\".join(errors)\n",
    "    if output == \"\":\n",
    "        return \"File content: OK!\"\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4a2d285-d250-4c21-aa6c-f0b9205ec100",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def search_entity(o, e_type, e_code):\n",
    "    if e_type == \"EXPERIMENT_TYPE\":\n",
    "        return o.get_collection_type(e_code)\n",
    "        \n",
    "    elif e_type == \"SAMPLE_TYPE\":\n",
    "        return o.get_object_type(e_code)\n",
    "    \n",
    "    elif e_type == \"DATASET_TYPE\":\n",
    "        return o.get_dataset_type(e_code)\n",
    "    \n",
    "def get_entity_list(o, entity_type):\n",
    "    if entity_type == \"EXPERIMENT_TYPE\":\n",
    "        return o.get_collection_types()\n",
    "    \n",
    "    elif entity_type == \"SAMPLE_TYPE\":\n",
    "        return o.get_object_types()\n",
    "    \n",
    "    elif entity_type == \"DATASET_TYPE\":\n",
    "        return o.get_dataset_types()\n",
    "    \n",
    "def compare_objects(obj1, obj2):\n",
    "    # Check if both are None or both are empty strings\n",
    "    if (obj1 is None and obj2 == \"\") or (obj1 == \"\" and obj2 is None):\n",
    "        return True\n",
    "    elif (obj1 == \"False\" and obj2 == \"FALSE\") or (obj1 == \"FALSE\" and obj2 == \"False\"):\n",
    "        return True\n",
    "    elif (obj1 == \"True\" and obj2 == \"TRUE\") or (obj1 == \"TRUE\" and obj2 == \"True\"):\n",
    "        return True\n",
    "    else:\n",
    "        return obj1 == obj2\n",
    "    \n",
    "def get_df_value(df, prop, attr):\n",
    "    column_name = 'propertyType'\n",
    "    \n",
    "    # Check if 'propertyType' column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        return None  # or handle this case appropriately\n",
    "\n",
    "    value_to_find = prop\n",
    "\n",
    "    # Create a boolean mask for rows where the condition is met\n",
    "    mask = df[column_name] == value_to_find\n",
    "\n",
    "    # Use the boolean mask to filter the DataFrame\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        return filtered_df[attr].iloc[0] if attr in filtered_df.columns else None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def check_entity_same_code(file_path, o, openbis_entity):\n",
    "    errors = []\n",
    "    description = \"\"\n",
    "    auto_code = \"\"\n",
    "    val_script = \"\"\n",
    "    prefix_code = \"\"\n",
    "\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    second_row_values = [cell.value for cell in sheet[2]]\n",
    "    \n",
    "    for term in second_row_values:\n",
    "        term_index = second_row_values.index(term)\n",
    "        if term == \"Code\":\n",
    "            entity_code = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Description\":\n",
    "            description = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Auto generate codes\":\n",
    "            auto_code = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Validation script\":\n",
    "            val_script = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Generated code prefix\":\n",
    "            prefix_code = sheet.cell(row=3, column=term_index + 1).value\n",
    "            \n",
    "        #format values to match\n",
    "        if (auto_code == True): auto_code = \"TRUE\"\n",
    "        if (auto_code == False): auto_code = \"FALSE\"\n",
    "        if (val_script == None): val_script = \"\"\n",
    "    \n",
    "    \n",
    "    openbis_description = openbis_entity.description\n",
    "    openbis_auto_code = openbis_entity.autoGeneratedCode\n",
    "    openbis_val_script = openbis_entity.validationPlugin\n",
    "    openbis_prefix_code = openbis_entity.generatedCodePrefix\n",
    "        \n",
    "    #cast values to STRING t match Excel data\n",
    "    if (openbis_auto_code == True): openbis_auto_code = \"TRUE\"\n",
    "    if (openbis_auto_code == False): openbis_auto_code = \"FALSE\"\n",
    "    if (openbis_val_script == None): openbis_val_script = \"\"\n",
    "        \n",
    "    #check description\n",
    "    if (description != openbis_description):\n",
    "        errors.append(f\"The Description of ('{entity_type}') '{entity_code}' has been changed compared to the previous version.\")\n",
    "        description_pattern = re.compile(r\".*//.*\")\n",
    "        if not description_pattern.match(description):\n",
    "            errors.append(\"Error: The Description of ('{entity_type}') '{entity_code}' should follow the schema: English Description + '//' + German Description.\")\n",
    "        \n",
    "    #check auto-generated codes\n",
    "    if (auto_code != openbis_auto_code):\n",
    "        errors.append(f\"The value of “Auto generate codes” of ('{entity_type}') '{entity_code}' has been changed from '{openbis_auto_code}' to '{auto_code}'.\")\n",
    "    \n",
    "    #check validation scripts\n",
    "    if (val_script == \"\" and openbis_val_script != \"\"):\n",
    "        errors.append(f\"The validation script '{openbis_val_script}' has been deleted from ('{entity_type}') '{entity_code}'.\")\n",
    "    elif (val_script != \"\" and openbis_val_script == \"\"):\n",
    "        errors.append(f\"A validation script '{val_script}' has been added to ('{entity_type}') '{entity_code}'.\")\n",
    "    elif (val_script != openbis_val_script):\n",
    "        errors.append(f\"The validation script of ('{entity_type}') '{entity_code}' has been changed from '{openbis_val_script}' to '{val_script}'.\")\n",
    "        \n",
    "    #check generated code prefix\n",
    "    if (prefix_code != openbis_prefix_code):\n",
    "        errors.append(f\"The Code Prefix of ('{entity_type}') '{entity_code}' has been changed from '{openbis_prefix_code}' to '{prefix_code}'.\")\n",
    "            \n",
    "            \n",
    "    #get assigned properties from the excel file\n",
    "    prop_headers = [cell.value for cell in sheet[4]]\n",
    "    entity_properties = []\n",
    "    term_index = prop_headers.index(\"Code\") + 1\n",
    "    term_letter = index_to_excel_column(term_index)\n",
    "        \n",
    "    for cell in sheet[term_letter][4:]:\n",
    "        if cell.value is not None:\n",
    "            entity_properties.append(cell.value)\n",
    "        \n",
    "    #get assigned properties from the openbis instance\n",
    "    openbis_entity_properties = []\n",
    "    for prop in openbis_entity.get_property_assignments():\n",
    "        openbis_entity_properties.append(prop.permId)\n",
    "    \n",
    "\n",
    "    # Remove None values from both lists before sorting\n",
    "    entity_properties = [prop for prop in entity_properties if prop is not None]\n",
    "    openbis_entity_properties = [prop for prop in openbis_entity_properties if prop is not None]\n",
    "\n",
    "    #check if the properties lists are the same\n",
    "    if sorted(entity_properties) != sorted(openbis_entity_properties):\n",
    "        errors.append(f\"The set of Property Types assigned to the ('{entity_type}') '{entity_code}' has been changed compared to the previous version.\")\n",
    "\n",
    "            \n",
    "    #check which properties has been added and removed\n",
    "    deleted_properties = []\n",
    "    added_properties = []\n",
    "        \n",
    "    deleted_properties = list(set(openbis_entity_properties) - set(entity_properties))\n",
    "    added_properties = list(set(entity_properties) - set(openbis_entity_properties))\n",
    "        \n",
    "    for d_prop in deleted_properties:\n",
    "        errors.append(f\"The Property type assignment '{d_prop}' has been removed.\")\n",
    "    for a_prop in added_properties:\n",
    "        errors.append(f\"The Property type assignment '{a_prop}' has been added.\")\n",
    "\n",
    "    #save dict with all the properties values from the entity in the instance\n",
    "    openbis_properties_data = {}\n",
    "    for prop in openbis_entity.get_property_assignments():\n",
    "        openbis_properties_data[prop.code] = {\n",
    "            \"label\": prop.label,\n",
    "            \"description\": prop.description,\n",
    "            \"dataType\": prop.dataType,\n",
    "            \"vocabulary\": prop.vocabulary if prop.vocabulary is not None else \"\",\n",
    "            \"metaData\" : prop.metaData\n",
    "        }\n",
    "            \n",
    "    #save dict with all the properties values from the excel metadata file\n",
    "    prop_headers = [cell.value for cell in sheet[4]]\n",
    "    properties_data = {}\n",
    "    term_index = prop_headers.index(\"Code\") + 1\n",
    "    term_letter = index_to_excel_column(term_index)\n",
    "        \n",
    "\n",
    "    for row in sheet.iter_rows(min_row=5, values_only=True):\n",
    "        code_value = row[term_index - 1]  # Index is 0-based\n",
    "        if code_value is not None:\n",
    "\n",
    "            properties_data[code_value] = {\n",
    "                'label': row[prop_headers.index('Property label')],\n",
    "                'description': row[prop_headers.index('Description')],\n",
    "                'dataType': row[prop_headers.index('Data type')],\n",
    "                \"vocabulary\": row[prop_headers.index('Vocabulary code')] if row[prop_headers.index('Vocabulary code')] is not None else \"\",\n",
    "                'metaData': {} if row[prop_headers.index('Metadata')] in (None, \"\") else row[prop_headers.index('Metadata')],\n",
    "                'mandatory': row[prop_headers.index('Mandatory')],\n",
    "                'section': row[prop_headers.index('Section')],\n",
    "                'plugin': row[prop_headers.index('Dynamic script')],\n",
    "                }\n",
    "\n",
    "    assigned_properties = openbis_entity.get_property_assignments().df\n",
    "    #properties present in the excel but not in openbis: not assigned\n",
    "    not_assigned_properties =  set(properties_data.keys()) - set(openbis_properties_data.keys())\n",
    "    \n",
    "    #compare both dicts with sets of properties to check the differences\n",
    "    for key in openbis_properties_data.keys() & properties_data.keys():\n",
    "        for assigned_field in [\"mandatory\", \"section\", \"plugin\"]:\n",
    "            excel_assigned = properties_data[key][assigned_field]\n",
    "            openbis_assigned = get_df_value(assigned_properties, key, assigned_field)\n",
    "            if not compare_objects(excel_assigned,openbis_assigned):\n",
    "                if assigned_field == \"mandatory\":\n",
    "                    if (str(openbis_assigned).upper() == \"FALSE\" and str(excel_assigned).upper() == \"TRUE\"):\n",
    "                        errors.append(f\"The value of the attribute 'Mandatory' of Property type {key} has been changed compared to the previous version from FALSE to TRUE.\")\n",
    "                    elif (str(openbis_assigned).upper() == \"TRUE\" and str(excel_assigned).upper() == \"FALSE\"):\n",
    "                        errors.append(f\"ERROR: The value of the attribute 'Mandatory' of Property type {key} has been changed compared to the previous version from TRUE to FALSE. This is NOT allowed\")\n",
    "                elif assigned_field == \"section\":\n",
    "                    errors.append(f\"The section of Property type {key} has been changed compared to the previous version from {openbis_assigned} to {excel_assigned}.\")\n",
    "                elif assigned_field == \"plugin\":\n",
    "                    if (openbis_assigned == \"\" or openbis_assigned == None) and (excel_assigned != \"\" or excel_assigned != None):\n",
    "                        errors.append(f\"WARNING: A dynamic property script ({excel_assigned}) has been added retrospectively to the Property type {key}.\")\n",
    "                    elif (str(openbis_assigned).upper() != str(excel_assigned).upper()):\n",
    "                        errors.append(f\"ERROR: The dynamic property script of Property type {key} has been changed or deleted compared to the previous version. This is NOT allowed\")\n",
    "                   \n",
    "        for field in [\"label\", \"description\", \"dataType\", \"vocabulary\", \"metaData\"]:\n",
    "            value1 = openbis_properties_data[key][field]\n",
    "            value2 = properties_data[key][field]\n",
    "            if not compare_objects(value1,value2):\n",
    "                if field == \"label\":\n",
    "                    errors.append(f\"The label of Property type {key} has been changed compared to the previous version from {value1} to {value2}.\")\n",
    "                elif field == \"description\":\n",
    "                    errors.append(f\"The description of Property type {key} has been changed compared to the previous version from {value1} to {value2}.\")\n",
    "                elif field == \"dataType\":\n",
    "                    errors.append(f\"WARNING: The data type of Property type {key} has been changed compared to the previous version from from {value1} to {value2}. This is only permissible for some cases, e.g., 'CONTROLLEDVOCABULARY' to 'VARCHAR'!\")\n",
    "                elif field == \"vocabulary\":\n",
    "                    errors.append(f\"ERROR: The vocabulary code of Property type {key} has been changed compared to the previous version from from {value1} to {value2}. This is not allowed.\")\n",
    "                elif field == \"metaData\":\n",
    "                    errors.append(f\"ERROR: The metadata of Property type {key} has been changed compared to the previous version from from {value1} to {value2}. This is not allowed.\")\n",
    "\n",
    "\n",
    "    for key in not_assigned_properties:\n",
    "        try:\n",
    "             prop_ob = o.get_property_type(key)\n",
    "             if not compare_objects(properties_data[key]['label'],prop_ob.label):\n",
    "                 errors.append(f\"The label of Property type {key} has been changed compared to the previous version from {prop_ob.label} to {properties_data[key]['label']}.\")\n",
    "             elif not compare_objects(properties_data[key]['description'],prop_ob.description):\n",
    "                 errors.append(f\"The description of Property type {key} has been changed compared to the previous version from {prop_ob.description} to {properties_data[key]['description']}.\")\n",
    "             elif not compare_objects(properties_data[key]['dataType'],prop_ob.dataType):\n",
    "                 errors.append(f\"The data type of Property type {key} has been changed compared to the previous version from {prop_ob.dataType} to {properties_data[key]['dataType']}. This is only permissible for some cases, e.g., 'CONTROLLEDVOCABULARY' to 'VARCHAR'!\")\n",
    "             elif not compare_objects(properties_data[key]['vocabulary'],prop_ob.vocabulary):\n",
    "                 errors.append(f\"The vocabulary code of Property type {key} has been changed compared to the previous version from {prop_ob.vocabulary} to {properties_data[key]['vocabulary']}. This is not allowed.\")\n",
    "             elif not compare_objects(properties_data[key]['metaData'],prop_ob.metaData):\n",
    "                 errors.append(f\"The metadata of Property type {key} has been changed compared to the previous version from {prop_ob.metaData} to {properties_data[key]['metaData']}. This is not allowed.\")\n",
    "        except ValueError:\n",
    "             continue\n",
    "        \n",
    "    workbook.close()\n",
    "    \n",
    "    return \"\\n\".join(errors)\n",
    "        \n",
    "def check_entity_diff_code(file_path, o):\n",
    "    errors = []\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    \n",
    "    openbis_entity_types = get_entity_list(o, entity_type)\n",
    "    \n",
    "    openbis_entity_properties = {}\n",
    "    \n",
    "    #get all the properties for each entity type from the instance, and save them in a dictionary\n",
    "    for etype in openbis_entity_types:\n",
    "        props_by_type = []\n",
    "        openbis_entity_properties[etype.code] = []\n",
    "        if etype.code != \"UNKNOWN\":\n",
    "            for prop in etype.get_property_assignments():\n",
    "                props_by_type.append(prop.permId)\n",
    "            openbis_entity_properties[etype.code] = props_by_type\n",
    "    \n",
    "    #get the assigned properties of the entity in the excel\n",
    "    entity_headers = [cell.value for cell in sheet[2]]\n",
    "    entity_properties = []\n",
    "    term_index = entity_headers.index(\"Code\") + 1\n",
    "    entity_code = sheet.cell(row=3, column=term_index).value\n",
    "    term_letter = index_to_excel_column(term_index)\n",
    "    \n",
    "    for cell in sheet[term_letter][4:]:\n",
    "        if cell.value is not None:\n",
    "            entity_properties.append(cell.value)\n",
    "            \n",
    "    for key, prop_list in openbis_entity_properties.items():\n",
    "        if set(prop_list) == set(entity_properties):\n",
    "            errors.append(f\"The {entity_type} '{entity_code}' is very similar to the existing {entity_type} '{key}'. Please consider whether you need to create a new entity type or whether you can re-use '{key}'\")\n",
    "    \n",
    "    return \"\\n\".join(errors)\n",
    "\n",
    "\n",
    "def check_prefix_sufix(file_path, o):\n",
    "    errors = []\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    \n",
    "    entity_headers = [cell.value for cell in sheet[2]]\n",
    "    term_index = entity_headers.index(\"Code\") + 1\n",
    "    entity_code = sheet.cell(row=3, column=term_index).value\n",
    "    \n",
    "    pattern = re.compile(r'^[A-Za-z0-9_.]+\\.[A-Za-z0-9_]+$')\n",
    "    \n",
    "    if pattern.match(entity_code):\n",
    "        parts = entity_code.rsplit('.', 1)\n",
    "        prefix = parts[0]\n",
    "        \n",
    "        prop_headers = [cell.value for cell in sheet[4]]\n",
    "        entity_properties = []\n",
    "        term_index = prop_headers.index(\"Code\") + 1\n",
    "        term_letter = index_to_excel_column(term_index)\n",
    "        \n",
    "        for cell in sheet[term_letter][4:]:\n",
    "            if cell.value is not None:\n",
    "                entity_properties.append(cell.value)\n",
    "        \n",
    "        #get assigned properties from the openbis instance\n",
    "        try:\n",
    "            prefix_entity = search_entity(o, entity_type, prefix)\n",
    "        except ValueError as e:\n",
    "            errors.append(f\"Entity type '{prefix}' is not present in the system, and cannot be the prefix of a new entity to be registered.\")\n",
    "            return \"\\n\".join(errors)\n",
    "        \n",
    "        prefix_properties = []\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties.append(prop.permId)\n",
    "            \n",
    "        #get the properties that are in the PREFIX but not in the SUFIX\n",
    "        difference = [value for value in prefix_properties if value not in entity_properties]\n",
    "        \n",
    "        prefix_properties_data = {}\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties_data[prop.code] = {\n",
    "                \"label\": prop.label,\n",
    "                \"description\": prop.description,\n",
    "                \"dataType\": prop.dataType,\n",
    "                \"vocabulary\": prop.vocabulary if prop.vocabulary is not None else \"\",\n",
    "                \"metaData\" : prop.metaData\n",
    "            }\n",
    "            \n",
    "        entity_properties_data = {}\n",
    "        for row in sheet.iter_rows(min_row=5, values_only=True):\n",
    "            code_value = row[term_index - 1]  # Index is 0-based\n",
    "            if code_value is not None:\n",
    "                entity_properties_data[code_value] = {\n",
    "                    'label': row[prop_headers.index('Property label')],\n",
    "                    'description': row[prop_headers.index('Description')],\n",
    "                    'dataType': row[prop_headers.index('Data type')],\n",
    "                    \"vocabulary\": row[prop_headers.index('Vocabulary code')] if row[prop_headers.index('Vocabulary code')] is not None else \"\",\n",
    "                    'metaData': {} if row[prop_headers.index('Metadata')] in (None, \"\") else row[prop_headers.index('Metadata')],\n",
    "                    }\n",
    "\n",
    "        changes = []\n",
    "        #compare both dicts with sets of properties to check the differences\n",
    "        for key in prefix_properties_data.keys() & entity_properties_data.keys():\n",
    "            for field in [\"label\", \"description\", \"dataType\", \"vocabulary\", \"metaData\"]:\n",
    "                value1 = prefix_properties_data[key][field]\n",
    "                value2 = entity_properties_data[key][field]\n",
    "                if value1 != value2:\n",
    "                    if field == \"label\":\n",
    "                        changes.append(f\"Change in label of Property type {key}.\")\n",
    "                    elif field == \"description\":\n",
    "                        changes.append(f\"Change in description of Property type {key}.\")\n",
    "                    elif field == \"dataType\":\n",
    "                        changes.append(f\"Change in data type of Property type {key}.\")\n",
    "                    elif field == \"vocabulary\":\n",
    "                        changes.append(f\"Change in vocabulary code of Property type {key}.\")\n",
    "                    elif field == \"metaData\":\n",
    "                        changes.append(f\"Change in metadata of Property type {key}.\")\n",
    "\n",
    "        if (len(difference) != 0) or (len(changes) != 0):\n",
    "            errors.append(f\"As a specification of the entity type {prefix}, the entity type {entity_code} must include all Property types of {prefix} without any changes.\")\n",
    "            errors.append(f\"The missing properties are: \")\n",
    "            missing = \", \".join(difference)\n",
    "            errors.append(missing)\n",
    "            errors.append(\"\\n\")\n",
    "            errors.append(f\"The changed property attributes are: \")\n",
    "            changed = \"\\n\".join(changes)\n",
    "            errors.append(changed)\n",
    "    \n",
    "            \n",
    "        check_prefix_prefix(o, prefix, entity_type, errors)\n",
    "    \n",
    "    \n",
    "    return \"\\n\".join(errors)\n",
    "\n",
    "\n",
    "def check_prefix_prefix(o, prefix, entity_type, errors):\n",
    "    if '.' in prefix:\n",
    "        # Split the string by the last dot\n",
    "        prefix_2, suffix = prefix.rsplit('.', 1)\n",
    "        \n",
    "        prefix_entity = search_entity(o, entity_type, prefix_2)\n",
    "        suffix_entity = search_entity(o, entity_type, suffix)\n",
    "        \n",
    "        prefix_properties = []\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties.append(prop.permId)\n",
    "            \n",
    "        suffix_properties = []\n",
    "        for prop in suffix_entity.get_property_assignments():\n",
    "            suffix_properties.append(prop.permId)\n",
    "            \n",
    "        difference = [value for value in prefix_properties if value not in suffix_properties]\n",
    "        \n",
    "        prefix_properties_data = {}\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties_data[prop.code] = {\n",
    "                \"label\": prop.label,\n",
    "                \"description\": prop.description,\n",
    "                \"dataType\": prop.dataType,\n",
    "                \"vocabulary\": prop.vocabulary if prop.vocabulary is not None else \"\",\n",
    "                \"metaData\" : prop.metaData\n",
    "            }\n",
    "            \n",
    "        suffix_properties_data = {}\n",
    "        for prop2 in suffix_entity.get_property_assignments():\n",
    "            suffix_properties_data[prop2.code] = {\n",
    "                \"label\": prop2.label,\n",
    "                \"description\": prop2.description,\n",
    "                \"dataType\": prop2.dataType,\n",
    "                \"vocabulary\": prop2.vocabulary if prop2.vocabulary is not None else \"\",\n",
    "                \"metaData\" : prop2.metaData\n",
    "            }\n",
    "            \n",
    "        changes = []\n",
    "        #compare both dicts with sets of properties to check the differences\n",
    "        for key in prefix_properties_data.keys() & suffix_properties_data.keys():\n",
    "            for field in [\"label\", \"description\", \"dataType\", \"vocabulary\", \"metaData\"]:\n",
    "                value1 = prefix_properties_data[key][field]\n",
    "                value2 = suffix_properties_data[key][field]\n",
    "                if value1 != value2:\n",
    "                    if field == \"label\":\n",
    "                        changes.append(f\"Change in label of Property type {key}.\")\n",
    "                    elif field == \"description\":\n",
    "                        changes.append(f\"Change in description of Property type {key}.\")\n",
    "                    elif field == \"dataType\":\n",
    "                        changes.append(f\"Change in data type of Property type {key}.\")\n",
    "                    elif field == \"vocabulary\":\n",
    "                        changes.append(f\"Change in vocabulary code of Property type {key}.\")\n",
    "                    elif field == \"metaData\":\n",
    "                        changes.append(f\"Change in metadata of Property type {key}.\")\n",
    "\n",
    "        if (len(difference) != 0) or (len(changes) != 0):\n",
    "            errors.append(f\"As a specification of the entity type {prefix}, the entity type {entity_code} must include all Property types of {prefix} without any changes.\")\n",
    "            missing = \", \".join(difference)\n",
    "            if missing != \"\":\n",
    "                errors.append(f\"The missing properties are: \")\n",
    "                errors.append(missing)\n",
    "            else:\n",
    "                errors.append(f\"There are no missing properties\")\n",
    "            errors.append(f\"The changed property attributes are: \")\n",
    "            changed = \"\\n\".join(changes)\n",
    "            errors.append(changed)\n",
    "\n",
    "\n",
    "        # Recursively call the function with the prefix\n",
    "        check_prefix_prefix(o, prefix_2, entity_type, errors)\n",
    "        \n",
    "        \n",
    "def entity_checker(file_path):\n",
    "    errors = []\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    entity_headers = [cell.value for cell in sheet[2]]\n",
    "    term_index = entity_headers.index(\"Code\") + 1\n",
    "    entity_code = sheet.cell(row=3, column=term_index).value\n",
    "    \n",
    "    try:\n",
    "        openbis_entity = search_entity(o, entity_type, entity_code)\n",
    "    except ValueError as e:\n",
    "        errors.append(f\"Entity type '{entity_code}' is a new entity type (not present in the system) to be registered.\")\n",
    "        openbis_entity = \"\"\n",
    "        \n",
    "    if (openbis_entity != \"\"):\n",
    "        errors.append(f\"Entity type '{entity_code}' already exists.\")\n",
    "        same_code_errors = check_entity_same_code(file_path, o, openbis_entity)\n",
    "        errors.append(same_code_errors)\n",
    "    else:\n",
    "        diff_code_errors = check_entity_diff_code(file_path, o)\n",
    "        errors.append(diff_code_errors)\n",
    "        \n",
    "    prefix_errors = check_prefix_sufix(file_path, o)\n",
    "    errors.append(prefix_errors)\n",
    "    \n",
    "    \n",
    "    return \"\\n\".join(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f9868fe1-9f10-4b5f-9932-0532532e83fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_csv_and_download():\n",
    "    url = o.url\n",
    "    \n",
    "    header = [\"INSTANCE\", \"DATE\"]\n",
    "    \n",
    "    instance = url.split(\"//\")[1].split(\".\")[0]\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    info = [instance, current_date]\n",
    "\n",
    "    print(f\"Checking contents in instance: {instance}\\n\")\n",
    "    \n",
    "    # Fetch data from the server\n",
    "    spaces = []\n",
    "    projects = []\n",
    "    experiment_types = []\n",
    "    object_types = []\n",
    "    material_types = []\n",
    "    dataset_types = []\n",
    "    vocabs = []\n",
    "    plugins = []\n",
    "    \n",
    "    print(f\"Listing SPACES in {instance}\\n\")\n",
    "    print(f\"Total number of SPACES: {str(o.get_spaces().totalCount)}\\n\")\n",
    "\n",
    "    for space in o.get_spaces():\n",
    "        print(f\"  {space}\")\n",
    "        spaces.append(space)\n",
    "\n",
    "    print(f\"\\nListing PROJECTS in {instance}\\n\")\n",
    "    print(f\"Total number of PROJECTS: {str(o.get_projects().totalCount)}\\n\")\n",
    "\n",
    "    for project in o.get_projects():\n",
    "        print(f\"  {project.code}\")\n",
    "        projects.append(project.code)\n",
    "\n",
    "    print(f\"\\nListing EXPERIMENT TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of EXPERIMENT TYPES: {str(o.get_experiment_types().totalCount)}\\n\")\n",
    "    \n",
    "    for exp in o.get_experiment_types():\n",
    "        print(f\"  {exp}\")\n",
    "        experiment_types.append(exp)\n",
    "    \n",
    "    print(f\"\\nListing OBJECT TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of OBJECT TYPES: {str(o.get_object_types().totalCount)}\\n\")\n",
    "\n",
    "    objs = []\n",
    "    for obj in o.get_object_types():\n",
    "        objs.append(obj)\n",
    "        print(f\"  {obj}\")\n",
    "        if obj.code != \"UNKNOWN\":\n",
    "            object_types.append(obj)\n",
    "\n",
    "    print(f\"\\nListing MATERIAL TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of MATERIAL TYPES: {str(o.get_material_types().totalCount)}\\n\")\n",
    "    \n",
    "    for material in o.get_material_types():\n",
    "        print(f\"  {material}\")\n",
    "        material_types.append(material)\n",
    "    \n",
    "    print(f\"\\nListing DATASET TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of DATASET TYPES: {str(o.get_dataset_types().totalCount)}\\n\")\n",
    "    \n",
    "    for dataset in o.get_dataset_types():\n",
    "        print(f\"  {dataset}\")\n",
    "        dataset_types.append(dataset)\n",
    "        \n",
    "    print(f\"\\nListing VOCABULARIES in {instance}\\n\")\n",
    "    print(f\"Total number of VOCABULARIES: {str(o.get_vocabularies().totalCount)}\\n\")\n",
    "    \n",
    "    for vocab in o.get_vocabularies():\n",
    "        print(f\"  {vocab.code}\")\n",
    "        vocabs.append(vocab.code)\n",
    "        \n",
    "    print(f\"\\nListing PLUGINS in {instance}\\n\")\n",
    "    print(f\"Total number of PLUGINS: {str(o.get_plugins().totalCount)}\\n\")\n",
    "    \n",
    "    for plug in o.get_plugins():\n",
    "        print(f\"  {plug.name}\")\n",
    "        plugins.append(plug.name)\n",
    "\n",
    "\n",
    "    masterdata_headers = [f\"SPACES ({len(spaces)})\", f\"PROJECTS ({len(projects)})\", f\"EXPERIMENT TYPES ({len(experiment_types)})\", \n",
    "                          f\"OBJECT TYPES ({len(object_types)})\", f\"DATASET TYPES ({len(dataset_types)})\",\n",
    "                          f\"VOCABULARIES ({len(vocabs)})\", f\"PLUGINS ({len(plugins)})\", f\"MATERIAL TYPES ({len(material_types)})\"]\n",
    "    \n",
    "    \n",
    "    # Combine master data into a list of lists\n",
    "    masterdata = [\n",
    "        spaces,\n",
    "        projects,\n",
    "        experiment_types,\n",
    "        object_types,\n",
    "        dataset_types,\n",
    "        vocabs,\n",
    "        plugins,\n",
    "        material_types\n",
    "    ]\n",
    "\n",
    "    # Directory name based on instance\n",
    "    directory = f\"{instance}_data\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # File path\n",
    "    filename = os.path.join(directory, f\"{instance}_{datetime.now().strftime('%d%m%Y')}.csv\")\n",
    "\n",
    "    \n",
    "    # Write data to CSV file\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the instance and date headers\n",
    "        writer.writerow([\"INSTANCE\", \"DATE\"])\n",
    "        \n",
    "        # Write the instance and date info\n",
    "        writer.writerow(info)\n",
    "        \n",
    "        # Write empty row\n",
    "        writer.writerow(\"\")\n",
    "        \n",
    "        # Write the master data headers\n",
    "        writer.writerow(masterdata_headers)\n",
    "        \n",
    "        # Determine the maximum length of the master data lists\n",
    "        max_length = max(len(data) for data in masterdata)\n",
    "        \n",
    "        # Write the master data vertically\n",
    "        for i in range(max_length):\n",
    "            row = []\n",
    "            for data in masterdata:\n",
    "                if i < len(data):\n",
    "                    row.append(data[i])\n",
    "                else:\n",
    "                    row.append(\"\")  # Append empty string if the list is shorter\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        # Write empty row\n",
    "        writer.writerow(\"\")\n",
    "        \n",
    "        writer.writerow([\"PROPERTY LIST BY OBJECT TYPE\"])\n",
    "            \n",
    "        # Write another header row with the content of object_types horizontally\n",
    "        writer.writerow(object_types)\n",
    "        \n",
    "        props_by_obj = []\n",
    "        \n",
    "        for obj in object_types:\n",
    "            if obj.code == \"UNKNOWN\":\n",
    "                continue\n",
    "            print(f\"\\nPROPERTY LIST for OBJECT {obj.code}\\n\")\n",
    "            props = []\n",
    "            for prop in obj.get_property_assignments():\n",
    "                print(f\"{prop.code} --> {str(prop.dataType).lower()}\")\n",
    "                props.append(f\"{prop.code} ({str(prop.dataType).lower()})\")\n",
    "            props_by_obj.append(props)\n",
    "            \n",
    "        # Determine the maximum length of the object properties\n",
    "        max_length_props = max(len(properties) for properties in props_by_obj)\n",
    "        \n",
    "        # Write the master data vertically\n",
    "        for i in range(max_length_props):\n",
    "            row = []\n",
    "            for prop_list in props_by_obj:\n",
    "                if i < len(prop_list):\n",
    "                    row.append(prop_list[i])\n",
    "                else:\n",
    "                    row.append(\"\")  # Append empty string if the list is shorter\n",
    "            writer.writerow(row)\n",
    "        \n",
    "    return f\"\\nCSV file '{filename}' has been created.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae730c9-eef4-423d-8292-66dfe969cb7d",
   "metadata": {},
   "source": [
    "## USE THE CHECKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491e890-9b78-405c-b85f-5aa3cee90b4a",
   "metadata": {},
   "source": [
    "Once executed all the function cells above, here we continue with the checker, where we will need to upload a file, and run the checker with that file against the selected instance in the beginning. If you just want to run the Masterdata Visualizer, you can ignore this part and go directly to the \"USE THE VISUALIZER\" cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59a4fb6-6be6-4c14-955a-df635a61cc9b",
   "metadata": {},
   "source": [
    "### UPLOAD THE EXCEL FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd6644-5e85-4a0c-afba-bfbf26e7fb52",
   "metadata": {},
   "source": [
    "Execute this cell below, and a button to upload a file will appear. Then, after clicking on the button, a window for selecting the desired file will appear. Once that you selected the file, you can continue to run the checker in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "024c26b0-64df-469e-88a0-fa3823dcab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16476522824f490393f46ae062ed2ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.xlsx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = widgets.FileUpload(\n",
    "    accept='.xlsx',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "def save_uploaded_file(uploader):\n",
    "    # Get the first uploaded file (since multiple=False, we expect only one file)\n",
    "    uploaded_file = uploader.value[0]\n",
    "    content = uploaded_file['content'].tobytes()\n",
    "    filename = uploaded_file['name']\n",
    "    \n",
    "    # Create a temporary file to save the uploaded content\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_file_path = os.path.join(temp_dir, filename)\n",
    "    \n",
    "    # Write the content to the temporary file\n",
    "    with open(temp_file_path, 'wb') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return temp_file_path\n",
    "\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e9f79-4230-4f99-989b-87ba39ec8446",
   "metadata": {},
   "source": [
    "### RUN THE CHECKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f645e36-34d1-4859-bf35-186fc7644d05",
   "metadata": {},
   "source": [
    "Here just run the cell below, and the Masterdata Checker will start to run. A loading bar will appear with the different procesess, and once that it finishes, all the checks will appear below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "64358cb4-73c0-4141-975d-afab8efd5dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ready to analyze\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8c7a03bae04b7087204d261303a554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/3 [00:00<?, ?task/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type: SAMPLE_TYPE\n",
      "\n",
      "NAME CHECKS:\n",
      "-------------\n",
      "File name: OK!\n",
      "\n",
      "CONTENT CHECKS:\n",
      "-------------\n",
      "Warning: It is recommended that the value of 'Generated code prefix' be the first three letters of each part of the 'Code' separated by dots ['.'].\n",
      "\n",
      "ENTITY CHECKS\n",
      "-------------\n",
      "Entity type 'CHEMICAL' already exists.\n",
      "The set of Property Types assigned to the ('SAMPLE_TYPE') 'CHEMICAL' has been changed compared to the previous version.\n",
      "The Property type assignment 'BA_DYN_TEST' has been removed.\n",
      "The label of Property type BAM_LOCATION has been changed compared to the previous version from BAM_LOCATION to BAM Location.\n",
      "The description of Property type BAM_LOCATION has been changed compared to the previous version from BAM Location//BAM Standort/Liegenschaft to BAM Location//BAM Liegenschaft.\n",
      "The description of Property type DESCRIPTION has been changed compared to the previous version from A Description to Short Description and/or Purpose//Kurzbeschreibung und/oder Zweck.\n",
      "WARNING: The data type of Property type DESCRIPTION has been changed compared to the previous version from from VARCHAR to MULTILINE_VARCHAR. This is only permissible for some cases, e.g., 'CONTROLLEDVOCABULARY' to 'VARCHAR'!\n",
      "The label of Property type BAM_HOUSE has been changed compared to the previous version from BAM_HOUSE to BAM House.\n",
      "The description of Property type BAM_HOUSE has been changed compared to the previous version from BAM House//BAM Gebäude/Haus to BAM House//BAM Haus.\n",
      "The label of Property type BAM_ROOM has been changed compared to the previous version from BAM_ROOM to BAM Room.\n",
      "The section of Property type NOTES has been changed compared to the previous version from Details to Additional Information.\n",
      "The description of Property type NOTES has been changed compared to the previous version from Notes to Notes//Notizen.\n",
      "WARNING: The data type of Property type NOTES has been changed compared to the previous version from from MULTILINE_VARCHAR to XML. This is only permissible for some cases, e.g., 'CONTROLLEDVOCABULARY' to 'VARCHAR'!\n",
      "ERROR: The metadata of Property type NOTES has been changed compared to the previous version from from {'custom_widget': 'Word Processor'} to {}. This is not allowed.\n",
      "The label of Property type BAM_LOCATION_COMPLETE has been changed compared to the previous version from BAM_LOCATION_COMPLETE to Complete BAM Location.\n",
      "The description of Property type BAM_LOCATION_COMPLETE has been changed compared to the previous version from Complete location (up to room level)//Komplette Ortsangabe (bis Raumlevel) to Complete BAM location (up to room level)//Komplette BAM-Ortsangabe (bis Raumlevel).\n",
      "The description of Property type $XMLCOMMENTS has been changed compared to the previous version from Comments log to Comments log//CMNTSLOG.\n",
      "The description of Property type $NAME has been changed compared to the previous version from Name to Name//Name.\n",
      "The label of Property type BAM_FLOOR has been changed compared to the previous version from BAM_FLOOR to BAM Floor.\n",
      "The description of Property type $ANNOTATIONS_STATE has been changed compared to the previous version from Annotations State to Annotations State//AnntStt.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if uploader.value:\n",
    "    file_path = save_uploaded_file(uploader)\n",
    "    print(f\"File ready to analyze\")\n",
    "else:\n",
    "    print(\"No file uploaded yet.\")\n",
    "\n",
    "file_name = file_path.split(\"\\\\\")[-1]\n",
    "\n",
    "# Initialize tqdm\n",
    "tasks = [\n",
    "    {\"name\": \"Name Check\", \"func\": name_checker, \"args\": (file_name,)},\n",
    "    {\"name\": \"Content Check\", \"func\": content_checker, \"args\": (file_path,)},\n",
    "    {\"name\": \"Entity Check\", \"func\": entity_checker, \"args\": (file_path,)}\n",
    "]\n",
    "\n",
    "with tqdm(total=len(tasks), desc=\"Overall Progress\", unit=\"task\") as pbar:\n",
    "    result_name = str(name_checker(file_name)[0])\n",
    "    name_ok = name_checker(file_name)[1]\n",
    "    pbar.update(1)\n",
    "    result_content = str(content_checker(file_path, name_ok))\n",
    "    pbar.update(1)\n",
    "    result_entity = str(entity_checker(file_path))\n",
    "    pbar.update(1)\n",
    "    result_format = \"\\nNAME CHECKS:\" + \"\\n-------------\\n\" + result_name + \"\\n\" + \"\\nCONTENT CHECKS:\" + \"\\n-------------\\n\" + result_content + \"\\n\" + \"\\nENTITY CHECKS\" + \"\\n-------------\\n\" + result_entity\n",
    "\n",
    "print(result_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392c880-8164-4af4-9960-b97503bd6b17",
   "metadata": {},
   "source": [
    "## USE THE VISUALIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f3fe3-1517-45fe-8fef-5069ee4050fa",
   "metadata": {},
   "source": [
    "Finally in this section we have the Masterdata Visualizer (which you can execute directly, without running the checker first). \n",
    "\n",
    "To run it, just execute the cell below, and it will generate a CSV file *in the same location* where this jupyter notebook is located (check your directory). \n",
    "\n",
    "More specifically, a folder with the name of the instance and data will appear (for example, \"main_data\" if you selected the main instance). Inside this folder, the different CSV files will be generated, once per day of execution (for example, executing it on the 30 of March 2024 in the main instance, the file inside the \"main_data\" folder will be called \"main_30032024.csv).\n",
    "\n",
    "Also, together with the CSV, we will have listed here all the information regarding the Masterdata content of the instance, if you just need a quick view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "396423f5-53e6-4db2-b33a-b01c1c8c8598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29444251ae804bb08c6d248d1a8b8ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating CSV:   0%|          | 0/100 [00:00<?, ?percent/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking contents in instance: devel\n",
      "\n",
      "Listing SPACES in devel\n",
      "\n",
      "Total number of SPACES: 13\n",
      "\n",
      "  DEFAULT\n",
      "  ELN_SETTINGS\n",
      "  STORAGE\n",
      "  DEFAULT_LAB_NOTEBOOK\n",
      "  METHODS\n",
      "  MATERIALS\n",
      "  STOCK_CATALOG\n",
      "  STOCK_ORDERS\n",
      "  PUBLICATIONS\n",
      "  JRAEDLER\n",
      "  DKOSZTYL\n",
      "  CMADARIA\n",
      "  RELATHMA\n",
      "\n",
      "Listing PROJECTS in devel\n",
      "\n",
      "Total number of PROJECTS: 15\n",
      "\n",
      "  DEFAULT\n",
      "  STORAGES\n",
      "  DEFAULT_PROJECT\n",
      "  PROTOCOLS\n",
      "  PRODUCTS\n",
      "  SUPPLIERS\n",
      "  REQUESTS\n",
      "  ORDERS\n",
      "  TEMPLATES\n",
      "  PUBLIC_REPOSITORIES\n",
      "  PRJ01\n",
      "  TEST\n",
      "  XYZ\n",
      "  TEST_PROJECT\n",
      "  DROPBOX_MANUAL\n",
      "\n",
      "Listing EXPERIMENT TYPES in devel\n",
      "\n",
      "Total number of EXPERIMENT TYPES: 4\n",
      "\n",
      "  UNKNOWN\n",
      "  COLLECTION\n",
      "  DEFAULT_EXPERIMENT\n",
      "  DROPBOX_COLLECTION\n",
      "\n",
      "Listing OBJECT TYPES in devel\n",
      "\n",
      "Total number of OBJECT TYPES: 20\n",
      "\n",
      "  UNKNOWN\n",
      "  SEARCH_QUERY\n",
      "  GENERAL_ELN_SETTINGS\n",
      "  ENTRY\n",
      "  GENERAL_PROTOCOL\n",
      "  EXPERIMENTAL_STEP\n",
      "  STORAGE\n",
      "  STORAGE_POSITION\n",
      "  SUPPLIER\n",
      "  PRODUCT\n",
      "  REQUEST\n",
      "  ORDER\n",
      "  PUBLICATION\n",
      "  LOCATION_C\n",
      "  BAM_LOCATION\n",
      "  TEST_AMOUNT\n",
      "  TEST_OBJECT\n",
      "  BAM_ACTIVITY\n",
      "  TASK\n",
      "  CHEMICAL\n",
      "\n",
      "Listing MATERIAL TYPES in devel\n",
      "\n",
      "Total number of MATERIAL TYPES: 0\n",
      "\n",
      "\n",
      "Listing DATASET TYPES in devel\n",
      "\n",
      "Total number of DATASET TYPES: 10\n",
      "\n",
      "  UNKNOWN\n",
      "  ELN_PREVIEW\n",
      "  RAW_DATA\n",
      "  PROCESSED_DATA\n",
      "  ANALYZED_DATA\n",
      "  ATTACHMENT\n",
      "  OTHER_DATA\n",
      "  SOURCE_CODE\n",
      "  ANALYSIS_NOTEBOOK\n",
      "  PUBLICATION_DATA\n",
      "\n",
      "Listing VOCABULARIES in devel\n",
      "\n",
      "Total number of VOCABULARIES: 23\n",
      "\n",
      "  $DEFAULT_COLLECTION_VIEWS\n",
      "  $ORDER.ORDER_STATUS\n",
      "  $PRODUCT.CURRENCY\n",
      "  $STORAGE.STORAGE_VALIDATION_LEVEL\n",
      "  $STORAGE_FORMAT\n",
      "  $STORAGE_POSITION.STORAGE_BOX_SIZE\n",
      "  $SUPPLIER.LANGUAGE\n",
      "  $SUPPLIER.PREFERRED_ORDER_METHOD\n",
      "  $WELL.COLOR_ENCODED_ANNOTATIONS\n",
      "  AMOUNT_UNIT\n",
      "  BAM_BUILDINGS_C\n",
      "  BAM_FIELD_OF_ACTIVITY\n",
      "  BAM_FLOOR\n",
      "  BAM_FOCUS_AREA\n",
      "  BAM_HOUSE\n",
      "  BAM_HOUSES_C\n",
      "  BAM_LEVELS_C\n",
      "  BAM_LOCATION\n",
      "  BAM_LOCATIONS_C\n",
      "  BAM_LOCATION_COMPLETE\n",
      "  BAM_ROOM\n",
      "  BAM_ROOMS_C\n",
      "  TEST_VOCAB\n",
      "\n",
      "Listing PLUGINS in devel\n",
      "\n",
      "Total number of PLUGINS: 24\n",
      "\n",
      "  DEFAULT_EXPERIMENT.date_range_validation\n",
      "  EXPERIMENTAL_STEP.date_range_validation\n",
      "  OBJECT.property_filled_validation\n",
      "  STORAGE_POSITION.storage_position_validation\n",
      "  bam_area_selector\n",
      "  bam_floor_split\n",
      "  bam_house_split\n",
      "  bam_location_split\n",
      "  bam_room_split\n",
      "  date_checker\n",
      "  floor_split\n",
      "  floor_split_c\n",
      "  floorv2_split\n",
      "  general_location\n",
      "  general_locationV2\n",
      "  house_split\n",
      "  house_splitV2\n",
      "  house_split_c\n",
      "  location_split_c\n",
      "  rectangle_area\n",
      "  room_number_split\n",
      "  room_number_splitV2\n",
      "  room_split\n",
      "  room_split_c\n",
      "\n",
      "PROPERTY LIST for OBJECT SEARCH_QUERY\n",
      "\n",
      "$NAME --> varchar\n",
      "$SEARCH_QUERY.SEARCH_CRITERIA --> xml\n",
      "$SEARCH_QUERY.FETCH_OPTIONS --> xml\n",
      "$SEARCH_QUERY.CUSTOM_DATA --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT GENERAL_ELN_SETTINGS\n",
      "\n",
      "$ELN_SETTINGS --> varchar\n",
      "\n",
      "PROPERTY LIST for OBJECT ENTRY\n",
      "\n",
      "$NAME --> varchar\n",
      "$SHOW_IN_PROJECT_OVERVIEW --> boolean\n",
      "$DOCUMENT --> multiline_varchar\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT GENERAL_PROTOCOL\n",
      "\n",
      "$NAME --> varchar\n",
      "FOR_WHAT --> multiline_varchar\n",
      "GENERAL_PROTOCOL.PROTOCOL_TYPE --> multiline_varchar\n",
      "GENERAL_PROTOCOL.MATERIALS --> multiline_varchar\n",
      "GENERAL_PROTOCOL.TIME_REQUIREMENT --> multiline_varchar\n",
      "PROCEDURE --> multiline_varchar\n",
      "GENERAL_PROTOCOL.PROTOCOL_EVALUATION --> multiline_varchar\n",
      "GENERAL_PROTOCOL.SPREADSHEET --> xml\n",
      "REFERENCE --> multiline_varchar\n",
      "PUBLICATION --> multiline_varchar\n",
      "NOTES --> multiline_varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT EXPERIMENTAL_STEP\n",
      "\n",
      "$NAME --> varchar\n",
      "$SHOW_IN_PROJECT_OVERVIEW --> boolean\n",
      "FINISHED_FLAG --> boolean\n",
      "START_DATE --> timestamp\n",
      "END_DATE --> timestamp\n",
      "EXPERIMENTAL_STEP.EXPERIMENTAL_GOALS --> multiline_varchar\n",
      "EXPERIMENTAL_STEP.EXPERIMENTAL_DESCRIPTION --> multiline_varchar\n",
      "EXPERIMENTAL_STEP.EXPERIMENTAL_RESULTS --> multiline_varchar\n",
      "EXPERIMENTAL_STEP.SPREADSHEET --> xml\n",
      "REFERENCE --> multiline_varchar\n",
      "PUBLICATION --> multiline_varchar\n",
      "NOTES --> multiline_varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT STORAGE\n",
      "\n",
      "$NAME --> varchar\n",
      "$STORAGE.ROW_NUM --> integer\n",
      "$STORAGE.COLUMN_NUM --> integer\n",
      "$STORAGE.BOX_NUM --> integer\n",
      "$STORAGE.STORAGE_SPACE_WARNING --> integer\n",
      "$STORAGE.BOX_SPACE_WARNING --> integer\n",
      "$STORAGE.STORAGE_VALIDATION_LEVEL --> controlledvocabulary\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT STORAGE_POSITION\n",
      "\n",
      "$STORAGE_POSITION.STORAGE_CODE --> varchar\n",
      "$STORAGE_POSITION.STORAGE_RACK_ROW --> integer\n",
      "$STORAGE_POSITION.STORAGE_RACK_COLUMN --> integer\n",
      "$STORAGE_POSITION.STORAGE_BOX_NAME --> varchar\n",
      "$STORAGE_POSITION.STORAGE_BOX_SIZE --> controlledvocabulary\n",
      "$STORAGE_POSITION.STORAGE_BOX_POSITION --> varchar\n",
      "$STORAGE_POSITION.STORAGE_USER --> varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT SUPPLIER\n",
      "\n",
      "$NAME --> varchar\n",
      "$SUPPLIER.COMPANY_ADDRESS_LINE_1 --> varchar\n",
      "$SUPPLIER.COMPANY_ADDRESS_LINE_2 --> varchar\n",
      "$SUPPLIER.COMPANY_FAX --> varchar\n",
      "$SUPPLIER.COMPANY_PHONE --> varchar\n",
      "$SUPPLIER.COMPANY_EMAIL --> varchar\n",
      "$SUPPLIER.COMPANY_LANGUAGE --> controlledvocabulary\n",
      "$SUPPLIER.CUSTOMER_NUMBER --> varchar\n",
      "SUPPLIER.COMPANY_CONTACT_NAME --> varchar\n",
      "SUPPLIER.COMPANY_CONTACT_EMAIL --> varchar\n",
      "SUPPLIER.PREFERRED_ORDER_METHOD --> controlledvocabulary\n",
      "SUPPLIER.URL --> hyperlink\n",
      "SUPPLIER.ADDITIONAL_INFORMATION --> varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT PRODUCT\n",
      "\n",
      "$NAME --> varchar\n",
      "PRODUCT.PRODUCT_SECONDARY_NAMES --> varchar\n",
      "PRODUCT.DESCRIPTION --> multiline_varchar\n",
      "PRODUCT.COMPANY --> varchar\n",
      "$PRODUCT.CATALOG_NUM --> varchar\n",
      "PRODUCT.CATEGORY --> varchar\n",
      "PRODUCT.HAZARD_STATEMENT --> varchar\n",
      "$PRODUCT.PRICE_PER_UNIT --> real\n",
      "$PRODUCT.CURRENCY --> controlledvocabulary\n",
      "PRODUCT.SIZE_OF_ITEM --> varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT REQUEST\n",
      "\n",
      "$NAME --> varchar\n",
      "$ORDERING.ORDER_STATUS --> controlledvocabulary\n",
      "REQUEST.PROJECT --> varchar\n",
      "REQUEST.DEPARTMENT --> varchar\n",
      "REQUEST.BUYER --> varchar\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT ORDER\n",
      "\n",
      "$NAME --> varchar\n",
      "$ORDER.SHIP_TO --> varchar\n",
      "$ORDER.BILL_TO --> varchar\n",
      "$ORDER.SHIP_ADDRESS --> varchar\n",
      "$ORDER.CONTACT_PHONE --> varchar\n",
      "$ORDER.CONTACT_FAX --> varchar\n",
      "$ORDERING.ORDER_STATUS --> controlledvocabulary\n",
      "ORDER.PRICE_PAID --> real\n",
      "$ORDER.ADDITIONAL_INFORMATION --> varchar\n",
      "$ORDER.ORDER_STATE --> varchar\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT PUBLICATION\n",
      "\n",
      "$NAME --> varchar\n",
      "$PUBLICATION.ORGANIZATION --> varchar\n",
      "$PUBLICATION.TYPE --> varchar\n",
      "$PUBLICATION.IDENTIFIER --> varchar\n",
      "$PUBLICATION.URL --> hyperlink\n",
      "$PUBLICATION.DESCRIPTION --> varchar\n",
      "$PUBLICATION.OPENBIS_RELATED_IDENTIFIERS --> varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT LOCATION_C\n",
      "\n",
      "ROOMC --> controlledvocabulary\n",
      "BUILDING --> controlledvocabulary\n",
      "HOUSEC --> controlledvocabulary\n",
      "LEVEL --> controlledvocabulary\n",
      "ROOM_NUMBER_C --> controlledvocabulary\n",
      "\n",
      "PROPERTY LIST for OBJECT BAM_LOCATION\n",
      "\n",
      "BAM_LOCATION_COMPLETE --> controlledvocabulary\n",
      "BAM_LOCATION --> controlledvocabulary\n",
      "BAM_HOUSE --> controlledvocabulary\n",
      "BAM_FLOOR --> controlledvocabulary\n",
      "BAM_ROOM --> controlledvocabulary\n",
      "TEST_VOCAB --> controlledvocabulary\n",
      "DESCRIPTION --> varchar\n",
      "\n",
      "PROPERTY LIST for OBJECT TEST_AMOUNT\n",
      "\n",
      "AMOUNT --> real\n",
      "AMOUNT_UNIT --> controlledvocabulary\n",
      "\n",
      "PROPERTY LIST for OBJECT TEST_OBJECT\n",
      "\n",
      "POSITIVE_NUMBER --> real\n",
      "PERCENTAGE --> real\n",
      "PROP1 --> real\n",
      "PROP2 --> real\n",
      "PROP3 --> real\n",
      "RECTANGLE_LENGTH --> real\n",
      "RECTANGLE_WIDTH --> real\n",
      "RECTANGLE_AREA --> real\n",
      "RECTANGLE_LENGTH_IN_M --> real\n",
      "RECTANGLE_WIDTH_IN_M --> real\n",
      "RECTANGLE_AREA_IN_QM --> real\n",
      "\n",
      "PROPERTY LIST for OBJECT BAM_ACTIVITY\n",
      "\n",
      "$NAME --> varchar\n",
      "BAM_FIELD_OF_ACTIVITY --> controlledvocabulary\n",
      "BAM_FOCUS_AREA --> multiline_varchar\n",
      "BAM_FOCUS_AREA_V2 --> controlledvocabulary\n",
      "\n",
      "PROPERTY LIST for OBJECT TASK\n",
      "\n",
      "$NAME --> varchar\n",
      "LAST_CHECK --> date\n",
      "FREQ_CHECK --> integer\n",
      "STATE_CHECK --> boolean\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "PROPERTY LIST for OBJECT CHEMICAL\n",
      "\n",
      "$NAME --> varchar\n",
      "ALIAS --> varchar\n",
      "IUPAC_NAME --> varchar\n",
      "CAS_NUMBER --> varchar\n",
      "MANUFACTURER --> varchar\n",
      "SUPPLIER --> varchar\n",
      "LOT_NUMBER --> varchar\n",
      "BARCODE_EXTERNAL --> varchar\n",
      "DESCRIPTION --> varchar\n",
      "HAZARDOUS_SUBSTANCE --> boolean\n",
      "BAM_ROOM --> controlledvocabulary\n",
      "BAM_FLOOR --> controlledvocabulary\n",
      "BAM_HOUSE --> controlledvocabulary\n",
      "BAM_LOCATION --> controlledvocabulary\n",
      "BAM_LOCATION_COMPLETE --> controlledvocabulary\n",
      "RESPONSIBLE_PERSON --> varchar\n",
      "BA_DYN_TEST --> controlledvocabulary\n",
      "MASS_MOLAR --> real\n",
      "CONCENTRATION --> real\n",
      "DENSITY_GRAM_PER_CUBIC_CM --> real\n",
      "DATE_BOTTLING --> date\n",
      "DATE_OPENING --> date\n",
      "DATE_EXPIRATION --> date\n",
      "SUBSTANCE_EMPTY --> boolean\n",
      "NOTES --> multiline_varchar\n",
      "$XMLCOMMENTS --> xml\n",
      "$ANNOTATIONS_STATE --> xml\n",
      "\n",
      "CSV file 'devel_data\\devel_19092024.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=100, desc=\"Generating CSV\", unit=\"percent\") as pbar:\n",
    "    for _ in range(10):\n",
    "        time.sleep(1)  # Simulate work being done in steps\n",
    "        pbar.update(10)\n",
    "\n",
    "    content = generate_csv_and_download()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfaa8c9-7723-4722-b2e1-ef4281f68f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

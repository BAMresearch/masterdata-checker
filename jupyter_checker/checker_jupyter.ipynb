{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c2d4bd-2c89-45fa-b369-ff29bc842232",
   "metadata": {},
   "source": [
    "# MASTERDATA CHECKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235db9ca-3a9b-475d-9b92-4e8e52895959",
   "metadata": {},
   "source": [
    "##### GUIDE:\n",
    "\n",
    "Just execute all the cells, on by one, and do what it says: Select instance, introduce user and password and click on login, etc.\n",
    "\n",
    "Execute all the methods in the section \"FUNCTIONS\" and run the checker and visualizer at the end of the notebook to see how it works. (For the checker, you need to upload a file, just an upload button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5afeb3-dfc4-4186-b7b7-d1d7f0a71549",
   "metadata": {},
   "source": [
    "## LOGIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1410b8-e416-4f4f-8c81-bc16d03234df",
   "metadata": {},
   "source": [
    "Here just execute this cell to import all the needed classes and packages tht this tool includes. If some of the import fails, try to execute \"pip install\" + package_name (name of the package that failed, for example, pip install ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f2ae08e-ea6a-4d91-8858-4edbb3bf4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pybis import Openbis\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, HTML\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7270de7-d7f8-4aa5-98e2-132411ad2d55",
   "metadata": {},
   "source": [
    "### Select the instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ed2a2-d049-4d9f-aba4-c21dd7a49b8f",
   "metadata": {},
   "source": [
    "After executing the following cell (you don't need to change anything, just run it), a dropdown selector will appear, where you will need just to select the desired openbis instance, and continue to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3317a7f8-a7b4-42e5-987e-68b38eedc868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29de31a6b684dea94770d813a7e581e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Instance:', options=('devel', 'main', 'schulung', 'test'), value='devel')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instance = widgets.Dropdown(\n",
    "    options=['devel', 'main', 'schulung', 'test'],\n",
    "    value='devel',\n",
    "    description='Instance:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601fe13-f7da-42a7-b35f-4c9cab6e5cee",
   "metadata": {},
   "source": [
    "### Enter username and password to login into selected openBIS instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067b3cf-6cd7-4bff-9919-af365ab55eda",
   "metadata": {},
   "source": [
    "Same as before, just execute the following cell without touching the code, and a login widget will appear, where you will need to introduce your username and password, and then click in the \"Login\" button. If something fails, you can use the cell after this one to login in a dfferent way. If it works, \"Login succesful!\" will appear under the button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aba19e23-a94a-4cd8-8da4-d9c5d1c924b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dcfbe562034fcea88171081d4975aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='User:', placeholder='Enter user name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0be8f204d54d20aa8a3a88c68c0ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Password(description='Password:', placeholder='Enter password')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8f1eee128f4642935f8593435bb804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Login', icon='login', style=ButtonStyle(), tooltip='Click to loginâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9caeb7122349d5958db0cbfb5993cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "usr = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter user name',\n",
    "    description='User:',\n",
    "    disabled=False   \n",
    ")\n",
    "psswd = widgets.Password(\n",
    "    value='',\n",
    "    placeholder='Enter password',\n",
    "    description='Password:',\n",
    "    disabled=False\n",
    ")\n",
    "output = widgets.Output()\n",
    "url = f\"https://{instance.value}.datastore.bam.de/\"\n",
    "o = Openbis(url)\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()  # Clear previous output\n",
    "        username = usr.value\n",
    "        password = psswd.value\n",
    "        o.login(username, password, save_token=True)\n",
    "        if(o.is_session_active()):\n",
    "            display(HTML(f\"<p>Login successful!</p>\"))\n",
    "        else:\n",
    "            display(HTML(f\"<p>Login failed: {str(e)}</p>\"))\n",
    "\n",
    "button = widgets.Button(\n",
    "    description=\"Login\",\n",
    "    button_style='success', \n",
    "    tooltip='Click to login in openBIS',\n",
    "    icon='login' \n",
    ")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "display(usr)\n",
    "display(psswd)\n",
    "display(button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6d2f2-e359-4696-b4c7-63280c75338f",
   "metadata": {},
   "source": [
    "Just execute this cell if the above login code fails! Not needed if it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4868fbd5-95cd-43f9-95e6-5d520ca4fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmadaria-240730113617513x89F835FBF39DE458CA3AC4E3D443A558'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = usr.value\n",
    "password = psswd.value\n",
    "\n",
    "url = f\"https://{instance.value}.datastore.bam.de/\"\n",
    "o = Openbis(url)\n",
    "o.login(username, password, save_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b038ff8-7e81-4f13-9dc5-e7d5fa8efb12",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc85ec-37ac-481c-8936-89ba4a15b2da",
   "metadata": {},
   "source": [
    "Here are the needed functions to execute the masterdata checker and visualizer. Execute all of them. It won't produce any output and the execution will be instant, imagine this as \"registering\" the functions. We will execute them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35cad684-a6a4-4116-bb54-20a708afbf65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def name_checker(file_path):\n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    \n",
    "    # Define the pattern for a valid file name\n",
    "    pattern = r\"^(collection_type|object_type|dataset_type|vocabulary)_([\\w.]+)_(v\\d+)_([a-zA-Z0-9]+(?:\\.[0-9]+)?)_([a-zA-Z0-9]+)\\.(xls|xlsx)$\"\n",
    " \n",
    "    # Check if the file name matches the pattern\n",
    "    match = re.match(pattern, file_name)\n",
    "\n",
    "    if match:\n",
    "        # Extract parts of the file name\n",
    "        entity_type, entity_name, version, division, contact_person, extension = match.groups()\n",
    "        #print(entity_type, entity_name, version, division, contact_person, extension)\n",
    "        return \"File name: OK!\"\n",
    "    else:\n",
    "        # Return specific errors and positions\n",
    "        errors = []\n",
    "        file_name = file_name.split(\".xls\")\n",
    "        \n",
    "        if len(file_name) < 2:\n",
    "            errors.append(\"Invalid file format. Only .xls and .xlsx accepted\")\n",
    "            return errors\n",
    "        \n",
    "        else:\n",
    "            file_parts = file_name[0].split(\"_\")\n",
    "            if len(file_parts) < 2:\n",
    "                errors.append(\"Invalid name format. The name should contain different fields separated by underscores (_). Consult the wiki to see which ones.\")\n",
    "                return errors\n",
    "            creator = file_parts.pop(-1)\n",
    "            section = file_parts.pop(-1)\n",
    "            version = file_parts.pop(-1)\n",
    "            etype = file_parts.pop(0)\n",
    "            if (etype == \"object\" or etype == \"collection\" or etype == \"dataset\"):\n",
    "                etype = etype + \"_\" + file_parts.pop(0)\n",
    "            code = \"_\".join(file_parts)\n",
    "            \n",
    "            if not re.match(r\"^(collection_type|object_type|dataset_type|vocabulary)$\", etype):\n",
    "                errors.append(\"Invalid entity type at position 1.\")\n",
    "            if not re.match(r\"^([\\w.]+)$\", code):\n",
    "                errors.append(\"Invalid entity name at position 2.\")\n",
    "            if not re.match(r\"^(v\\d+)$\", version):\n",
    "                errors.append(\"Invalid version at position 3.\")\n",
    "            if not re.match(r\"^([a-zA-Z0-9]+(?:\\.[0-9]+)?)$\", section):\n",
    "                errors.append(\"Invalid division at position 4.\")\n",
    "            if not re.match(r\"^[a-zA-Z0-9]+$\", creator):\n",
    "                errors.append(\"Invalid contact person at position 5.\")\n",
    "            \n",
    "            return \"\\n\".join(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6ad617c-c264-4f09-a806-e6ac9f849686",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def index_to_excel_column(index):\n",
    "    column = ''\n",
    "    while index > 0:\n",
    "        index, remainder = divmod(index - 1, 26)\n",
    "        column = chr(65 + remainder) + column\n",
    "    return column\n",
    "\n",
    "\n",
    "def check_properties(sheet, errors):\n",
    "    expected_terms = [\n",
    "        \"Version\",\n",
    "        \"Code\",\n",
    "        \"Description\",\n",
    "        \"Mandatory\",\n",
    "        \"Show in edit views\",\n",
    "        \"Section\",\n",
    "        \"Property label\",\n",
    "        \"Data type\",\n",
    "        \"Vocabulary code\"\n",
    "    ]\n",
    "    row_headers = [cell.value for cell in sheet[4]]\n",
    "    for term in expected_terms:\n",
    "        if (term not in row_headers):\n",
    "            if term in (\"Mandatory\",\"Show in edit views\",\"Section\"):\n",
    "                errors.append(f\"Warning: '{term}' not found in the properties headers.\")\n",
    "            else:\n",
    "                errors.append(f\"Error: '{term}' not found in the properties headers.\")\n",
    "        else:\n",
    "             # Find the index of the term in the second row\n",
    "             term_index = row_headers.index(term) + 1\n",
    "             term_letter = index_to_excel_column(term_index)\n",
    "             #print(term_index)\n",
    "             \n",
    "             # Check the column below \"Version\"\n",
    "             if term == \"Version\":\n",
    "                 column_below_version = []\n",
    "                 for cell in sheet[term_letter][4:]:\n",
    "                     if cell.value is not None:\n",
    "                         column_below_version.append(cell.value)\n",
    "                     else:\n",
    "                         pass\n",
    "\n",
    "                 # Check if any value in the column is not an integer\n",
    "                 non_integer_indices = [i + 5 for i, cell in enumerate(column_below_version) if not (str(cell).isnumeric() or \"$\" in str(cell))]\n",
    "                 if non_integer_indices:\n",
    "                     # Append an error indicating the positions (row numbers) that are not integers\n",
    "                     errors.append(f\"Error: Values not valid found in the 'Version' column (they should be Integers) at row(s): {', '.join(map(str, non_integer_indices))}\")\n",
    "\n",
    "            # Check the column below \"Code\"\n",
    "             elif term == \"Code\":\n",
    "                column_below_code = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_code.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_codes = [i + 5 for i, cell in enumerate(column_below_code) if not (re.match(r'^\\$?[A-Z0-9_.]+$', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_codes:\n",
    "                    # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                    errors.append(f\"Error: Invalid code found in the '{term}' column at row(s): {', '.join(map(str, invalid_codes))}\")\n",
    "                    \n",
    "                #check that all the properties of the object are different using a set (unique terms):\n",
    "                if len(set(column_below_code)) != len(column_below_code):\n",
    "                    seen_props = set()\n",
    "                    repeated_props = set()\n",
    "                    for prop in column_below_code:\n",
    "                        if prop in seen_props:\n",
    "                            repeated_props.add(prop)\n",
    "                        else:\n",
    "                            seen_props.add(prop)\n",
    "                    errors.append(f\"Error: The following properties are repeated: {repeated_props}. Please, delete the duplicates, and leave just one occurence\")\n",
    "\n",
    "            \n",
    "            \n",
    "            # Check the cell below \"Description\"\n",
    "             elif term == \"Description\":\n",
    "                column_below_description = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_description.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_indices = [i + 5 for i, cell in enumerate(column_below_description) if not (re.match(r'.*//.*', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_indices:\n",
    "                    errors.append(f\"Error: Invalid value(s) found in the '{term}' column at row(s): {', '.join(map(str, invalid_indices))}. Description should follow the schema: English Description + '//' + German Description.\")\n",
    "\n",
    "            # Check the cell below \"Mandatory\"\n",
    "             elif term == \"Mandatory\":\n",
    "                column_below_mandatory = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_mandatory.append(str(cell.value).upper())\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_mandatory = [i + 5 for i, cell in enumerate(column_below_mandatory) if (cell not in [\"TRUE\", \"FALSE\"] and \"$\" not in str(cell))]\n",
    "                if invalid_mandatory:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_mandatory))}. Accepted values: TRUE, FALSE\")\n",
    "\n",
    "            # Check the cell below \"Show in edit views\"\n",
    "             elif term == \"Show in edit views\":\n",
    "                column_below_show = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_show.append(str(cell.value).upper())\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_show = [i + 5 for i, cell in enumerate(column_below_show) if (cell not in [\"TRUE\", \"FALSE\"] and \"$\" not in str(cell))]\n",
    "                if invalid_show:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_show))}. Accepted values: TRUE, FALSE\")\n",
    "\n",
    "            # Check the cell below \"Section\"\n",
    "             elif term == \"Section\":\n",
    "                column_below_section = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_section.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_section = [i + 5 for i, cell in enumerate(column_below_section) if not (re.match(r'.*', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_section:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_section))}. Specify the section as text format\")\n",
    "\n",
    "            # Check the cell below \"Property label\"\n",
    "             elif term == \"Property label\":\n",
    "                column_below_label = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_label.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_label = [i + 5 for i, cell in enumerate(column_below_label) if not (re.match(r'.*', str(cell)) or \"$\" in str(cell))]\n",
    "                if invalid_label:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_label))}. Specify the property label as text format\")\n",
    "\n",
    "            # Check the cell below \"Data type\"\n",
    "             elif term == \"Data type\":\n",
    "                column_below_type = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_type.append(str(cell.value).upper())\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_type = [i + 5 for i, cell in enumerate(column_below_type) if (cell not in [\"INTEGER\", \"REAL\", \"VARCHAR\", \"MULTILINE_VARCHAR\", \"HYPERLINK\", \"BOOLEAN\", \"CONTROLLEDVOCABULARY\", \"XML\", \"TIMESTAMP\", \"DATE\", \"SAMPLE\"] and \"$\" not in str(cell))]\n",
    "                if invalid_type:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_type))}. Accepted types: INTEGER, REAL, VARCHAR, MULTILINE_VARCHAR, HYPERLINK, BOOLEAN, CONTROLLEDVOCABULARY, XML, TIMESTAMP, DATE, SAMPLE\")\n",
    "\n",
    "            # Check the column below \"Vocabulary code\"\n",
    "             elif term == \"Vocabulary code\":\n",
    "                column_below_vocab = sheet[term_letter][4:]\n",
    "                invalid_vocab = [i + 5 for i, cell in enumerate(column_below_vocab) if cell.value and not (re.match(r'^\\$?[A-Z0-9_.]', str(cell.value)) or \"$\" not in str(cell))]\n",
    "                if invalid_vocab:\n",
    "                    # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                    errors.append(f\"Error: Invalid vocabulary code found in the '{term}' column at row(s): {', '.join(map(str, invalid_vocab))}\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def check_vocab_terms(sheet, errors):\n",
    "    expected_terms = [\n",
    "        \"Version\",\n",
    "        \"Code\",\n",
    "        \"Label\"\n",
    "        \"Description\"\n",
    "    ]\n",
    "    row_headers = [cell.value for cell in sheet[4]]\n",
    "    for term in expected_terms:\n",
    "        if term not in row_headers:\n",
    "            errors.append(f\"Error: '{term}' not found in the vocabulary term headers.\")\n",
    "        else:\n",
    "             # Find the index of the term in the second row\n",
    "             term_index = row_headers.index(term) + 1\n",
    "             term_letter = index_to_excel_column(term_index)\n",
    "             #print(term_index)\n",
    "             \n",
    "             # Check the column below \"Version\"\n",
    "             if term == \"Version\":\n",
    "                 column_below_version = []\n",
    "                 for cell in sheet[term_letter][4:]:\n",
    "                     if cell.value is not None:\n",
    "                         column_below_version.append(cell.value)\n",
    "                     else:\n",
    "                         pass\n",
    "\n",
    "                 # Check if any value in the column is not an integer\n",
    "                 non_integer_indices = [i + 5 for i, cell in enumerate(column_below_version) if not str(cell).isnumeric()]\n",
    "                 if non_integer_indices:\n",
    "                     # Append an error indicating the positions (row numbers) that are not integers\n",
    "                     errors.append(f\"Error: Values not valid found in the 'Version' column (they should be Integers) at row(s): {', '.join(map(str, non_integer_indices))}\")\n",
    "\n",
    "            # Check the column below \"Code\"\n",
    "             elif term == \"Code\":\n",
    "                column_below_code = []\n",
    "                for cell in sheet[term_letter][4:]:\n",
    "                    if cell.value is not None:\n",
    "                        column_below_code.append(cell.value)\n",
    "                    else:\n",
    "                        pass\n",
    "                invalid_codes = [i + 5 for i, cell in enumerate(column_below_code) if not re.match(r'^\\$?[A-Z0-9_.]+$', str(cell))]\n",
    "                if invalid_codes:\n",
    "                    # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                    errors.append(f\"Error: Invalid code found in the '{term}' column at row(s): {', '.join(map(str, invalid_codes))}\")\n",
    "                \n",
    "                #check that all the properties of the object are different using a set (unique terms):\n",
    "                if len(set(column_below_code)) != len(column_below_code):\n",
    "                    seen_terms = set()\n",
    "                    repeated_terms = set()\n",
    "                    for term in column_below_code:\n",
    "                        if term in seen_terms:\n",
    "                            repeated_terms.add(term)\n",
    "                        else:\n",
    "                            seen_terms.add(term)\n",
    "                    errors.append(f\"Error: The following vocabulary terms are repeated: {repeated_terms}. Please, delete the duplicates, and leave just one occurence\")\n",
    "\n",
    "            \n",
    "            \n",
    "            # Check the cell below \"Description\"\n",
    "             elif term == \"Description\":\n",
    "                column_below_description = sheet[term_letter][4:]\n",
    "                invalid_description = [i + 5 for i, cell in enumerate(column_below_description) if cell.value and not re.match(r'.*//.*', str(cell.value))]\n",
    "                if invalid_description:\n",
    "                    errors.append(f\"Error: Invalid value(s) found in the '{term}' column at row(s): {', '.join(map(str, invalid_description))}. Description should follow the schema: English Description + '//' + German Description.\")\n",
    "\n",
    "            # Check the cell below \"Mandatory\"\n",
    "             elif term == \"Label\":\n",
    "                column_below_label = sheet[term_letter][4:]\n",
    "                invalid_label = [i + 5 for i, cell in enumerate(column_below_label) if cell.value and not re.match(r'.*', str(cell.value))]\n",
    "                if invalid_label:\n",
    "                    errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_section))}. Specify the label as text format\")\n",
    "            \n",
    "    return \"\\n\".join(errors)\n",
    "\n",
    "#file_path = 'C:/Users/cmadaria/Documents/Projects/Type checker/object_type_CHEMICAL_v1_S.3_relathma.xlsx'\n",
    "def content_checker(file_path):\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    errors = []\n",
    "    file_name = file_path.split(\"\\\\\")[-1]\n",
    "    file_name = file_name.split(\".xls\")\n",
    "    file_parts = file_name[0].split(\"_\")\n",
    "    file_parts.pop(-1)\n",
    "    file_parts.pop(-1)\n",
    "    version = file_parts.pop(-1)\n",
    "    etype = file_parts.pop(0)\n",
    "    if (etype == \"object\" or etype == \"collection\" or etype == \"dataset\"):\n",
    "        etype = etype + \"_\" + file_parts.pop(0)\n",
    "    code = \"_\".join(file_parts)\n",
    "\n",
    "    sheet = workbook.active\n",
    "    \n",
    "    filtered_rows = []\n",
    "    \n",
    "    for row in sheet.iter_rows(min_row=1, values_only=True):\n",
    "    # Check if any cell in the row contains \"$\"\n",
    "        if any(\"$\" in str(cell) for cell in row):\n",
    "            filtered_rows.append([\"$\" + str(cell) if cell is not None else None for cell in row])\n",
    "        else:\n",
    "            # If the row passed the check, add it to the filtered list\n",
    "            filtered_rows.append(row)\n",
    "    \n",
    "    #remove all the rows in the sheet\n",
    "    sheet.delete_rows(0, sheet.max_row)\n",
    "\n",
    "    # Append the filtered rows to the sheet\n",
    "    for row_data in filtered_rows:\n",
    "        sheet.append(row_data)\n",
    "\n",
    "    # Access a specific cell (e.g., cell A1)\n",
    "    cell_value_A1 = sheet['A1'].value\n",
    "    print(f\"Entity Type: {cell_value_A1}\")\n",
    "    \n",
    "    entity_types = [\"SAMPLE_TYPE\", \"EXPERIMENT_TYPE\", \"DATASET_TYPE\", \"PROPERTY_TYPE\", \"VOCABULARY_TYPE\"]\n",
    "    if cell_value_A1 not in entity_types:\n",
    "        errors.append(\"The entity type (cell A1) should be one of the following: SAMPLE_TYPE, EXPERIMENT_TYPE, DATASET_TYPE, PROPERTY_TYPE, VOCABULARY_TYPE\")\n",
    "        return \"\\n\".join(errors)\n",
    "    else:\n",
    "        if cell_value_A1 == \"SAMPLE_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\",\n",
    "                \"Validation script\",\n",
    "                \"Generated code prefix\",\n",
    "                \"Auto generate codes\",\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the entity headers.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term)\n",
    "\n",
    "                     # Check the cell below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        cell_below_version = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if str(cell_below_version.value) != version[1:]:\n",
    "                            errors.append(\"Error: The version should be the same one indicated in the file name\")\n",
    "\n",
    "                    # Check the cell below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        cell_below_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if cell_below_code.value != code:\n",
    "                            errors.append(\"Error: The code should be the same one indicated in the file name\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        cell_below_description = sheet.cell(row=3, column=term_index + 1)\n",
    "                        description_pattern = re.compile(r\".*//.*\")\n",
    "                        if not description_pattern.match(cell_below_description.value):\n",
    "                            errors.append(\"Error: Description should follow the schema: English Description + '//' + German Description.\")\n",
    "\n",
    "                    # Check the cell below \"Generated code prefix\"\n",
    "                     elif term == \"Generated code prefix\":\n",
    "                        cell_below_generated_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        code_replace = code.replace('_', '.').split('.')\n",
    "                        ext_code = [word[:3].upper() for word in code_replace]\n",
    "                        generated_code = '.'.join(ext_code)\n",
    "                        if cell_below_generated_code.value != generated_code:\n",
    "                            errors.append(\"Warning: It is recommended that the value of 'Generated code prefix' be the first three letters of each part of the 'Code' separated by dots ['.'].\")\n",
    "\n",
    "                    # Check the cell below \"Validation script\"\n",
    "                     elif term == \"Validation script\":\n",
    "                        cell_below_validation = sheet.cell(row=3, column=term_index + 1)\n",
    "                        validation_pattern = re.compile(r\"^[A-Za-z0-9_]+\\.py$\")\n",
    "                        if cell_below_validation.value and not validation_pattern.match(cell_below_validation.value):\n",
    "                             errors.append(\"Error: Validation script should follow the schema: Words and/or numbers separated by '_' and ending in '.py'\")\n",
    "\n",
    "\n",
    "                    # Check the cell below \"Auto generate codes\"\n",
    "                     elif term == \"Auto generate codes\":\n",
    "                        cell_below_auto_generate = sheet.cell(row=3, column=term_index + 1)\n",
    "                        auto_code = cell_below_auto_generate.value\n",
    "                        if (auto_code == True): auto_code = \"TRUE\"\n",
    "                        if (auto_code == False): auto_code = \"FALSE\"\n",
    "                        if auto_code not in [\"TRUE\", \"FALSE\"]:\n",
    "                            errors.append(\"Error: Value below 'Auto generate codes' should be 'TRUE' or 'FALSE'.\")\n",
    "            \n",
    "            errors = check_properties(sheet, errors)      \n",
    "            \n",
    "        elif cell_value_A1 == \"EXPERIMENT_TYPE\" or cell_value_A1 == \"DATASET_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\",\n",
    "                \"Validation script\"\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the second row.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term)\n",
    "\n",
    "                     # Check the cell below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        cell_below_version = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if str(cell_below_version.value) != version[1:]:\n",
    "                            errors.append(\"Error: The version should be the same one indicated in the file name\")\n",
    "\n",
    "                    # Check the cell below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        cell_below_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if cell_below_code.value != code:\n",
    "                            errors.append(\"Error: The code should be the same one indicated in the file name\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        cell_below_description = sheet.cell(row=3, column=term_index + 1)\n",
    "                        description_pattern = re.compile(r\".*//.*\")\n",
    "                        if not description_pattern.match(cell_below_description.value):\n",
    "                            errors.append(\"Error: Description should follow the schema: English Description + '//' + German Description.\")\n",
    "            \n",
    "            \n",
    "                    # Check the cell below \"Validation script\"\n",
    "                     elif term == \"Validation script\":\n",
    "                        cell_below_validation = sheet.cell(row=3, column=term_index + 1)\n",
    "                        validation_pattern = re.compile(r\"^[A-Za-z0-9_]+\\.py$\")\n",
    "                        if cell_below_validation.value and not validation_pattern.match(cell_below_validation.value):\n",
    "                            errors.append(\"Error: Validation script should follow the schema: Words and/or numbers separated by '_' and ending in '.py'\")\n",
    "\n",
    "            errors = check_properties(sheet, errors) \n",
    "            \n",
    "        elif cell_value_A1 == \"VOCABULARY_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\"\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the second row.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term)\n",
    "\n",
    "                     # Check the cell below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        cell_below_version = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if str(cell_below_version.value) != version[1:]:\n",
    "                            errors.append(\"Error: The version should be the same one indicated in the file name. Value found: {cell_below_version.value}\")\n",
    "\n",
    "                    # Check the cell below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        cell_below_code = sheet.cell(row=3, column=term_index + 1)\n",
    "                        if cell_below_code.value != code:\n",
    "                            errors.append(\"Error: The code should be the same one indicated in the file name. Value found: {cell_below_code.value}\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        cell_below_description = sheet.cell(row=3, column=term_index + 1)\n",
    "                        description_pattern = re.compile(r\".*//.*\")\n",
    "                        if not description_pattern.match(cell_below_description.value):\n",
    "                            errors.append(\"Error: Description should follow the schema: English Description + '//' + German Description. Value found: {cell_below_description.value}\")\n",
    "            \n",
    "            errors = check_vocab_terms(sheet, errors)\n",
    "\n",
    "        elif cell_value_A1 == \"PROPERTY_TYPE\":\n",
    "            expected_terms = [\n",
    "                \"Version\",\n",
    "                \"Code\",\n",
    "                \"Description\",\n",
    "                \"Mandatory\",\n",
    "                \"Show in edit views\",\n",
    "                \"Section\",\n",
    "                \"Property label\",\n",
    "                \"Data type\",\n",
    "                \"Vocabulary code\"\n",
    "            ]\n",
    "            second_row_values = [cell.value for cell in sheet[2]]\n",
    "            for term in expected_terms:\n",
    "                if term not in second_row_values:\n",
    "                    errors.append(f\"Error: '{term}' not found in the second row.\")\n",
    "                else:\n",
    "                     # Find the index of the term in the second row\n",
    "                     term_index = second_row_values.index(term) + 1\n",
    "\n",
    "\n",
    "                     # Check the column below \"Version\"\n",
    "                     if term == \"Version\":\n",
    "                        column_below_version = sheet[term_index][2:]\n",
    "                        # Check if any value in the column is not an integer\n",
    "                        non_integer_indices = [i + 3 for i, cell in enumerate(column_below_version) if not isinstance(cell.value, int)]\n",
    "                        if non_integer_indices:\n",
    "                            # Append an error indicating the positions (row numbers) that are not integers\n",
    "                            errors.append(f\"Error: Values not valid found in the 'Version' column (they should be Integers) at row(s): {', '.join(map(str, non_integer_indices))}. Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the column below \"Code\"\n",
    "                     elif term == \"Code\":\n",
    "                        column_below_code = sheet[term_index][2:]\n",
    "                        invalid_codes = [i + 3 for i, cell in enumerate(column_below_code) if not re.match(r'^\\$?[A-Z0-9_.]+$', str(cell.value))]\n",
    "                        if invalid_codes:\n",
    "                            # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                            errors.append(f\"Error: Invalid code found in the '{term}' column at row(s): {', '.join(map(str, invalid_codes))}. Value found: {cell.value}\")\n",
    "                    \n",
    "                    \n",
    "                    # Check the cell below \"Description\"\n",
    "                     elif term == \"Description\":\n",
    "                        column_below_description = sheet[term_index][2:]\n",
    "                        invalid_indices = [i + 3 for i, cell in enumerate(column_below_code) if not re.match(r'.*//.*', str(cell.value))]\n",
    "                        if invalid_indices:\n",
    "                            errors.append(f\"Error: Invalid value(s) found in the '{term}' column at row(s): {', '.join(map(str, invalid_indices))}. Description should follow the schema: English Description + '//' + German Description. Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the cell below \"Mandatory\"\n",
    "                     elif term == \"Mandatory\":\n",
    "                        column_below_mandatory = sheet[term_index][2:]\n",
    "                        invalid_mandatory = [i + 3 for i, cell in enumerate(column_below_mandatory) if cell.value not in [\"TRUE\", \"FALSE\"]]\n",
    "                        if invalid_mandatory:\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_mandatory))}. Accepted values: TRUE, FALSE. Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the cell below \"Show in edit views\"\n",
    "                     elif term == \"Show in edit views\":\n",
    "                        column_below_show = sheet[term_index][2:]\n",
    "                        invalid_show = [i + 3 for i, cell in enumerate(column_below_show) if cell.value not in [\"TRUE\", \"FALSE\"]]\n",
    "                        if invalid_show:\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_show))}. Accepted values: TRUE, FALSE. Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the cell below \"Section\"\n",
    "                     elif term == \"Section\":\n",
    "                        column_below_section = sheet[term_index][2:]\n",
    "                        invalid_section = [i + 3 for i, cell in enumerate(column_below_section) if not re.match(r'.*', str(cell.value))]\n",
    "                        if invalid_section:\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_section))}. Specify the section as text format. Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the cell below \"Property label\"\n",
    "                     elif term == \"Property label\":\n",
    "                        column_below_label = sheet[term_index][2:]\n",
    "                        invalid_label = [i + 3 for i, cell in enumerate(column_below_label) if not re.match(r'.*', str(cell.value))]\n",
    "                        if invalid_label:\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_label))}. Specify the property label as text format. Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the cell below \"Data type\"\n",
    "                     elif term == \"Data type\":\n",
    "                        column_below_type = sheet[term_index][2:]\n",
    "                        invalid_type = [i + 3 for i, cell in enumerate(column_below_type) if cell.value not in [\"INTEGER\", \"REAL\", \"VARCHAR\", \"MULTILINE_VARCHAR\", \"HYPERLINK\", \"BOOLEAN\", \"CONTROLLEDVOCABULARY\", \"XML\", \"TIMESTAMP\", \"DATE\", \"SAMPLE\"]]\n",
    "                        if invalid_type:\n",
    "                            errors.append(f\"Error: Invalid value found in the '{term}' column at row(s): {', '.join(map(str, invalid_type))}. Accepted types: INTEGER, REAL, VARCHAR, MULTILINE_VARCHAR, HYPERLINK, BOOLEAN, CONTROLLEDVOCABULARY, XML, TIMESTAMP, DATE, SAMPLE.  Value found: {cell.value}\")\n",
    "\n",
    "                    # Check the column below \"Vocabulary code\"\n",
    "                     elif term == \"Vocabulary code\":\n",
    "                        column_below_vocab = sheet[term_index][2:]\n",
    "                        invalid_vocab = [i + 3 for i, cell in enumerate(column_below_vocab) if cell.value is not None and not re.match(r'^\\$?[A-Z0-9_.]+$', str(cell.value))]\n",
    "                        if invalid_vocab:\n",
    "                            # Append an error indicating the positions (row numbers) with invalid values for the current term\n",
    "                            errors.append(f\"Error: Invalid vocabulary code found in the '{term}' column at row(s): {', '.join(map(str, invalid_vocab))}. Value found: {cell.value}\")\n",
    "\n",
    "\n",
    "    # Close the workbook after use\n",
    "    workbook.close()\n",
    "    output = \"\\n\".join(errors)\n",
    "    if output == \"\":\n",
    "        return \"File content: OK!\"\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4a2d285-d250-4c21-aa6c-f0b9205ec100",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def search_entity(o, e_type, e_code):\n",
    "    if e_type == \"EXPERIMENT_TYPE\":\n",
    "        return o.get_collection_type(e_code)\n",
    "        \n",
    "    elif e_type == \"SAMPLE_TYPE\":\n",
    "        return o.get_object_type(e_code)\n",
    "    \n",
    "    elif e_type == \"DATASET_TYPE\":\n",
    "        return o.get_dataset_type(e_code)\n",
    "    \n",
    "def get_entity_list(o, entity_type):\n",
    "    if entity_type == \"EXPERIMENT_TYPE\":\n",
    "        return o.get_collection_types()\n",
    "    \n",
    "    elif entity_type == \"SAMPLE_TYPE\":\n",
    "        return o.get_object_types()\n",
    "    \n",
    "    elif entity_type == \"DATASET_TYPE\":\n",
    "        return o.get_dataset_types()\n",
    "    \n",
    "def compare_objects(obj1, obj2):\n",
    "    # Check if both are None or both are empty strings\n",
    "    if (obj1 is None and obj2 == \"\") or (obj1 == \"\" and obj2 is None):\n",
    "        return True\n",
    "    elif (obj1 == \"False\" and obj2 == \"FALSE\") or (obj1 == \"FALSE\" and obj2 == \"False\"):\n",
    "        return True\n",
    "    elif (obj1 == \"True\" and obj2 == \"TRUE\") or (obj1 == \"TRUE\" and obj2 == \"True\"):\n",
    "        return True\n",
    "    else:\n",
    "        return obj1 == obj2\n",
    "    \n",
    "def get_df_value(df, prop, attr):\n",
    "    column_name = 'propertyType'\n",
    "    \n",
    "    # Check if 'propertyType' column exists in the DataFrame\n",
    "    if column_name not in df.columns:\n",
    "        return None  # or handle this case appropriately\n",
    "\n",
    "    value_to_find = prop\n",
    "\n",
    "    # Create a boolean mask for rows where the condition is met\n",
    "    mask = df[column_name] == value_to_find\n",
    "\n",
    "    # Use the boolean mask to filter the DataFrame\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        return filtered_df[attr].iloc[0] if attr in filtered_df.columns else None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def check_entity_same_code(file_path, o, openbis_entity):\n",
    "    errors = []\n",
    "    description = \"\"\n",
    "    auto_code = \"\"\n",
    "    val_script = \"\"\n",
    "    prefix_code = \"\"\n",
    "\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    second_row_values = [cell.value for cell in sheet[2]]\n",
    "    \n",
    "    for term in second_row_values:\n",
    "        term_index = second_row_values.index(term)\n",
    "        if term == \"Code\":\n",
    "            entity_code = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Description\":\n",
    "            description = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Auto generate codes\":\n",
    "            auto_code = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Validation script\":\n",
    "            val_script = sheet.cell(row=3, column=term_index + 1).value\n",
    "        elif term == \"Generated code prefix\":\n",
    "            prefix_code = sheet.cell(row=3, column=term_index + 1).value\n",
    "            \n",
    "        #format values to match\n",
    "        if (auto_code == True): auto_code = \"TRUE\"\n",
    "        if (auto_code == False): auto_code = \"FALSE\"\n",
    "        if (val_script == None): val_script = \"\"\n",
    "    \n",
    "    \n",
    "    openbis_description = openbis_entity.description\n",
    "    openbis_auto_code = openbis_entity.autoGeneratedCode\n",
    "    openbis_val_script = openbis_entity.validationPlugin\n",
    "    openbis_prefix_code = openbis_entity.generatedCodePrefix\n",
    "        \n",
    "    #cast values to STRING t match Excel data\n",
    "    if (openbis_auto_code == True): openbis_auto_code = \"TRUE\"\n",
    "    if (openbis_auto_code == False): openbis_auto_code = \"FALSE\"\n",
    "    if (openbis_val_script == None): openbis_val_script = \"\"\n",
    "        \n",
    "    #check description\n",
    "    if (description != openbis_description):\n",
    "        errors.append(f\"The Description of ('{entity_type}') '{entity_code}' has been changed compared to the previous version.\")\n",
    "        description_pattern = re.compile(r\".*//.*\")\n",
    "        if not description_pattern.match(description):\n",
    "            errors.append(\"Error: The Description of ('{entity_type}') '{entity_code}' should follow the schema: English Description + '//' + German Description.\")\n",
    "        \n",
    "    #check auto-generated codes\n",
    "    if (auto_code != openbis_auto_code):\n",
    "        errors.append(f\"The value of â€œAuto generate codesâ€ of ('{entity_type}') '{entity_code}' has been changed from '{openbis_auto_code}' to '{auto_code}'.\")\n",
    "    \n",
    "    #check validation scripts\n",
    "    if (val_script == \"\" and openbis_val_script != \"\"):\n",
    "        errors.append(f\"The validation script '{openbis_val_script}' has been deleted from ('{entity_type}') '{entity_code}'.\")\n",
    "    elif (val_script != \"\" and openbis_val_script == \"\"):\n",
    "        errors.append(f\"A validation script '{val_script}' has been added to ('{entity_type}') '{entity_code}'.\")\n",
    "    elif (val_script != openbis_val_script):\n",
    "        errors.append(f\"The validation script of ('{entity_type}') '{entity_code}' has been changed from '{openbis_val_script}' to '{val_script}'.\")\n",
    "        \n",
    "    #check generated code prefix\n",
    "    if (prefix_code != openbis_prefix_code):\n",
    "        errors.append(f\"The Code Prefix of ('{entity_type}') '{entity_code}' has been changed from '{openbis_prefix_code}' to '{prefix_code}'.\")\n",
    "            \n",
    "            \n",
    "    #get assigned properties from the excel file\n",
    "    prop_headers = [cell.value for cell in sheet[4]]\n",
    "    entity_properties = []\n",
    "    term_index = prop_headers.index(\"Code\") + 1\n",
    "    term_letter = index_to_excel_column(term_index)\n",
    "        \n",
    "    for cell in sheet[term_letter][4:]:\n",
    "        if cell.value is not None:\n",
    "            entity_properties.append(cell.value)\n",
    "        \n",
    "    #get assigned properties from the openbis instance\n",
    "    openbis_entity_properties = []\n",
    "    for prop in openbis_entity.get_property_assignments():\n",
    "        openbis_entity_properties.append(prop.permId)\n",
    "    \n",
    "\n",
    "    # Remove None values from both lists before sorting\n",
    "    entity_properties = [prop for prop in entity_properties if prop is not None]\n",
    "    openbis_entity_properties = [prop for prop in openbis_entity_properties if prop is not None]\n",
    "\n",
    "    #check if the properties lists are the same\n",
    "    if sorted(entity_properties) != sorted(openbis_entity_properties):\n",
    "        errors.append(f\"The set of Property Types assigned to the ('{entity_type}') '{entity_code}' has been changed compared to the previous version.\")\n",
    "\n",
    "            \n",
    "    #check which properties has been added and removed\n",
    "    deleted_properties = []\n",
    "    added_properties = []\n",
    "        \n",
    "    deleted_properties = list(set(openbis_entity_properties) - set(entity_properties))\n",
    "    added_properties = list(set(entity_properties) - set(openbis_entity_properties))\n",
    "        \n",
    "    for d_prop in deleted_properties:\n",
    "        errors.append(f\"The Property type assignment '{d_prop}' has been removed.\")\n",
    "    for a_prop in added_properties:\n",
    "        errors.append(f\"The Property type assignment '{a_prop}' has been added.\")\n",
    "\n",
    "    #save dict with all the properties values from the entity in the instance\n",
    "    openbis_properties_data = {}\n",
    "    for prop in openbis_entity.get_property_assignments():\n",
    "        openbis_properties_data[prop.code] = {\n",
    "            \"label\": prop.label,\n",
    "            \"description\": prop.description,\n",
    "            \"dataType\": prop.dataType,\n",
    "            \"vocabulary\": prop.vocabulary if prop.vocabulary is not None else \"\",\n",
    "            \"metaData\" : prop.metaData\n",
    "        }\n",
    "            \n",
    "    #save dict with all the properties values from the excel metadata file\n",
    "    prop_headers = [cell.value for cell in sheet[4]]\n",
    "    properties_data = {}\n",
    "    term_index = prop_headers.index(\"Code\") + 1\n",
    "    term_letter = index_to_excel_column(term_index)\n",
    "        \n",
    "\n",
    "    for row in sheet.iter_rows(min_row=5, values_only=True):\n",
    "        code_value = row[term_index - 1]  # Index is 0-based\n",
    "        if code_value is not None:\n",
    "\n",
    "            properties_data[code_value] = {\n",
    "                'label': row[prop_headers.index('Property label')],\n",
    "                'description': row[prop_headers.index('Description')],\n",
    "                'dataType': row[prop_headers.index('Data type')],\n",
    "                \"vocabulary\": row[prop_headers.index('Vocabulary code')] if row[prop_headers.index('Vocabulary code')] is not None else \"\",\n",
    "                'metaData': {} if row[prop_headers.index('Metadata')] in (None, \"\") else row[prop_headers.index('Metadata')],\n",
    "                'mandatory': row[prop_headers.index('Mandatory')],\n",
    "                'section': row[prop_headers.index('Section')],\n",
    "                'plugin': row[prop_headers.index('Dynamic script')],\n",
    "                }\n",
    "\n",
    "    assigned_properties = openbis_entity.get_property_assignments().df\n",
    "    #properties present in the excel but not in openbis: not assigned\n",
    "    not_assigned_properties =  set(properties_data.keys()) - set(openbis_properties_data.keys())\n",
    "    \n",
    "    #compare both dicts with sets of properties to check the differences\n",
    "    for key in openbis_properties_data.keys() & properties_data.keys():\n",
    "        for assigned_field in [\"mandatory\", \"section\", \"plugin\"]:\n",
    "            excel_assigned = properties_data[key][assigned_field]\n",
    "            openbis_assigned = get_df_value(assigned_properties, key, assigned_field)\n",
    "            if not compare_objects(excel_assigned,openbis_assigned):\n",
    "                if assigned_field == \"mandatory\":\n",
    "                    if (str(openbis_assigned).upper() == \"FALSE\" and str(excel_assigned).upper() == \"TRUE\"):\n",
    "                        errors.append(f\"The value of the attribute 'Mandatory' of Property type {key} has been changed compared to the previous version from FALSE to TRUE.\")\n",
    "                    elif (str(openbis_assigned).upper() == \"TRUE\" and str(excel_assigned).upper() == \"FALSE\"):\n",
    "                        errors.append(f\"ERROR: The value of the attribute 'Mandatory' of Property type {key} has been changed compared to the previous version from TRUE to FALSE. This is NOT allowed\")\n",
    "                elif assigned_field == \"section\":\n",
    "                    errors.append(f\"The section of Property type {key} has been changed compared to the previous version from {openbis_assigned} to {excel_assigned}.\")\n",
    "                elif assigned_field == \"plugin\":\n",
    "                    if (openbis_assigned == \"\" or openbis_assigned == None) and (excel_assigned != \"\" or excel_assigned != None):\n",
    "                        errors.append(f\"WARNING: A dynamic property script ({excel_assigned}) has been added retrospectively to the Property type {key}.\")\n",
    "                    elif (str(openbis_assigned).upper() != str(excel_assigned).upper()):\n",
    "                        errors.append(f\"ERROR: The dynamic property script of Property type {key} has been changed or deleted compared to the previous version. This is NOT allowed\")\n",
    "                   \n",
    "        for field in [\"label\", \"description\", \"dataType\", \"vocabulary\", \"metaData\"]:\n",
    "            value1 = openbis_properties_data[key][field]\n",
    "            value2 = properties_data[key][field]\n",
    "            if not compare_objects(value1,value2):\n",
    "                if field == \"label\":\n",
    "                    errors.append(f\"The label of Property type {key} has been changed compared to the previous version from {value1} to {value2}.\")\n",
    "                elif field == \"description\":\n",
    "                    errors.append(f\"The description of Property type {key} has been changed compared to the previous version from {value1} to {value2}.\")\n",
    "                elif field == \"dataType\":\n",
    "                    errors.append(f\"WARNING: The data type of Property type {key} has been changed compared to the previous version from from {value1} to {value2}. This is only permissible for some cases, e.g., 'CONTROLLEDVOCABULARY' to 'VARCHAR'!\")\n",
    "                elif field == \"vocabulary\":\n",
    "                    errors.append(f\"ERROR: The vocabulary code of Property type {key} has been changed compared to the previous version from from {value1} to {value2}. This is not allowed.\")\n",
    "                elif field == \"metaData\":\n",
    "                    errors.append(f\"ERROR: The metadata of Property type {key} has been changed compared to the previous version from from {value1} to {value2}. This is not allowed.\")\n",
    "\n",
    "\n",
    "    for key in not_assigned_properties:\n",
    "        try:\n",
    "             prop_ob = o.get_property_type(key)\n",
    "             if not compare_objects(properties_data[key]['label'],prop_ob.label):\n",
    "                 errors.append(f\"The label of Property type {key} has been changed compared to the previous version from {prop_ob.label} to {properties_data[key]['label']}.\")\n",
    "             elif not compare_objects(properties_data[key]['description'],prop_ob.description):\n",
    "                 errors.append(f\"The description of Property type {key} has been changed compared to the previous version from {prop_ob.description} to {properties_data[key]['description']}.\")\n",
    "             elif not compare_objects(properties_data[key]['dataType'],prop_ob.dataType):\n",
    "                 errors.append(f\"The data type of Property type {key} has been changed compared to the previous version from {prop_ob.dataType} to {properties_data[key]['dataType']}. This is only permissible for some cases, e.g., 'CONTROLLEDVOCABULARY' to 'VARCHAR'!\")\n",
    "             elif not compare_objects(properties_data[key]['vocabulary'],prop_ob.vocabulary):\n",
    "                 errors.append(f\"The vocabulary code of Property type {key} has been changed compared to the previous version from {prop_ob.vocabulary} to {properties_data[key]['vocabulary']}. This is not allowed.\")\n",
    "             elif not compare_objects(properties_data[key]['metaData'],prop_ob.metaData):\n",
    "                 errors.append(f\"The metadata of Property type {key} has been changed compared to the previous version from {prop_ob.metaData} to {properties_data[key]['metaData']}. This is not allowed.\")\n",
    "        except ValueError:\n",
    "             continue\n",
    "        \n",
    "    workbook.close()\n",
    "    \n",
    "    return \"\\n\".join(errors)\n",
    "        \n",
    "def check_entity_diff_code(file_path, o):\n",
    "    errors = []\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    \n",
    "    openbis_entity_types = get_entity_list(o, entity_type)\n",
    "    \n",
    "    openbis_entity_properties = {}\n",
    "    \n",
    "    #get all the properties for each entity type from the instance, and save them in a dictionary\n",
    "    for etype in openbis_entity_types:\n",
    "        props_by_type = []\n",
    "        openbis_entity_properties[etype.code] = []\n",
    "        if etype.code != \"UNKNOWN\":\n",
    "            for prop in etype.get_property_assignments():\n",
    "                props_by_type.append(prop.permId)\n",
    "            openbis_entity_properties[etype.code] = props_by_type\n",
    "    \n",
    "    #get the assigned properties of the entity in the excel\n",
    "    entity_headers = [cell.value for cell in sheet[2]]\n",
    "    entity_properties = []\n",
    "    term_index = entity_headers.index(\"Code\") + 1\n",
    "    entity_code = sheet.cell(row=3, column=term_index).value\n",
    "    term_letter = index_to_excel_column(term_index)\n",
    "    \n",
    "    for cell in sheet[term_letter][4:]:\n",
    "        if cell.value is not None:\n",
    "            entity_properties.append(cell.value)\n",
    "            \n",
    "    for key, prop_list in openbis_entity_properties.items():\n",
    "        if set(prop_list) == set(entity_properties):\n",
    "            errors.append(f\"The {entity_type} '{entity_code}' is very similar to the existing {entity_type} '{key}'. Please consider whether you need to create a new entity type or whether you can re-use '{key}'\")\n",
    "    \n",
    "    return \"\\n\".join(errors)\n",
    "\n",
    "\n",
    "def check_prefix_sufix(file_path, o):\n",
    "    errors = []\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    \n",
    "    entity_headers = [cell.value for cell in sheet[2]]\n",
    "    term_index = entity_headers.index(\"Code\") + 1\n",
    "    entity_code = sheet.cell(row=3, column=term_index).value\n",
    "    \n",
    "    pattern = re.compile(r'^[A-Za-z0-9_.]+\\.[A-Za-z0-9_]+$')\n",
    "    \n",
    "    if pattern.match(entity_code):\n",
    "        parts = entity_code.rsplit('.', 1)\n",
    "        prefix = parts[0]\n",
    "        \n",
    "        prop_headers = [cell.value for cell in sheet[4]]\n",
    "        entity_properties = []\n",
    "        term_index = prop_headers.index(\"Code\") + 1\n",
    "        term_letter = index_to_excel_column(term_index)\n",
    "        \n",
    "        for cell in sheet[term_letter][4:]:\n",
    "            if cell.value is not None:\n",
    "                entity_properties.append(cell.value)\n",
    "        \n",
    "        #get assigned properties from the openbis instance\n",
    "        try:\n",
    "            prefix_entity = search_entity(o, entity_type, prefix)\n",
    "        except ValueError as e:\n",
    "            errors.append(f\"Entity type '{prefix}' is not present in the system, and cannot be the prefix of a new entity to be registered.\")\n",
    "            return \"\\n\".join(errors)\n",
    "        \n",
    "        prefix_properties = []\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties.append(prop.permId)\n",
    "            \n",
    "        #get the properties that are in the PREFIX but not in the SUFIX\n",
    "        difference = [value for value in prefix_properties if value not in entity_properties]\n",
    "        \n",
    "        prefix_properties_data = {}\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties_data[prop.code] = {\n",
    "                \"label\": prop.label,\n",
    "                \"description\": prop.description,\n",
    "                \"dataType\": prop.dataType,\n",
    "                \"vocabulary\": prop.vocabulary if prop.vocabulary is not None else \"\",\n",
    "                \"metaData\" : prop.metaData\n",
    "            }\n",
    "            \n",
    "        entity_properties_data = {}\n",
    "        for row in sheet.iter_rows(min_row=5, values_only=True):\n",
    "            code_value = row[term_index - 1]  # Index is 0-based\n",
    "            if code_value is not None:\n",
    "                entity_properties_data[code_value] = {\n",
    "                    'label': row[prop_headers.index('Property label')],\n",
    "                    'description': row[prop_headers.index('Description')],\n",
    "                    'dataType': row[prop_headers.index('Data type')],\n",
    "                    \"vocabulary\": row[prop_headers.index('Vocabulary code')] if row[prop_headers.index('Vocabulary code')] is not None else \"\",\n",
    "                    'metaData': {} if row[prop_headers.index('Metadata')] in (None, \"\") else row[prop_headers.index('Metadata')],\n",
    "                    }\n",
    "\n",
    "        changes = []\n",
    "        #compare both dicts with sets of properties to check the differences\n",
    "        for key in prefix_properties_data.keys() & entity_properties_data.keys():\n",
    "            for field in [\"label\", \"description\", \"dataType\", \"vocabulary\", \"metaData\"]:\n",
    "                value1 = prefix_properties_data[key][field]\n",
    "                value2 = entity_properties_data[key][field]\n",
    "                if value1 != value2:\n",
    "                    if field == \"label\":\n",
    "                        changes.append(f\"Change in label of Property type {key}.\")\n",
    "                    elif field == \"description\":\n",
    "                        changes.append(f\"Change in description of Property type {key}.\")\n",
    "                    elif field == \"dataType\":\n",
    "                        changes.append(f\"Change in data type of Property type {key}.\")\n",
    "                    elif field == \"vocabulary\":\n",
    "                        changes.append(f\"Change in vocabulary code of Property type {key}.\")\n",
    "                    elif field == \"metaData\":\n",
    "                        changes.append(f\"Change in metadata of Property type {key}.\")\n",
    "\n",
    "        if (len(difference) != 0) or (len(changes) != 0):\n",
    "            errors.append(f\"As a specification of the entity type {prefix}, the entity type {entity_code} must include all Property types of {prefix} without any changes.\")\n",
    "            errors.append(f\"The missing properties are: \")\n",
    "            missing = \", \".join(difference)\n",
    "            errors.append(missing)\n",
    "            errors.append(\"\\n\")\n",
    "            errors.append(f\"The changed property attributes are: \")\n",
    "            changed = \"\\n\".join(changes)\n",
    "            errors.append(changed)\n",
    "    \n",
    "            \n",
    "        check_prefix_prefix(o, prefix, entity_type, errors)\n",
    "    \n",
    "    \n",
    "    return \"\\n\".join(errors)\n",
    "\n",
    "\n",
    "def check_prefix_prefix(o, prefix, entity_type, errors):\n",
    "    if '.' in prefix:\n",
    "        # Split the string by the last dot\n",
    "        prefix_2, suffix = prefix.rsplit('.', 1)\n",
    "        \n",
    "        prefix_entity = search_entity(o, entity_type, prefix_2)\n",
    "        suffix_entity = search_entity(o, entity_type, suffix)\n",
    "        \n",
    "        prefix_properties = []\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties.append(prop.permId)\n",
    "            \n",
    "        suffix_properties = []\n",
    "        for prop in suffix_entity.get_property_assignments():\n",
    "            suffix_properties.append(prop.permId)\n",
    "            \n",
    "        difference = [value for value in prefix_properties if value not in suffix_properties]\n",
    "        \n",
    "        prefix_properties_data = {}\n",
    "        for prop in prefix_entity.get_property_assignments():\n",
    "            prefix_properties_data[prop.code] = {\n",
    "                \"label\": prop.label,\n",
    "                \"description\": prop.description,\n",
    "                \"dataType\": prop.dataType,\n",
    "                \"vocabulary\": prop.vocabulary if prop.vocabulary is not None else \"\",\n",
    "                \"metaData\" : prop.metaData\n",
    "            }\n",
    "            \n",
    "        suffix_properties_data = {}\n",
    "        for prop2 in suffix_entity.get_property_assignments():\n",
    "            suffix_properties_data[prop2.code] = {\n",
    "                \"label\": prop2.label,\n",
    "                \"description\": prop2.description,\n",
    "                \"dataType\": prop2.dataType,\n",
    "                \"vocabulary\": prop2.vocabulary if prop2.vocabulary is not None else \"\",\n",
    "                \"metaData\" : prop2.metaData\n",
    "            }\n",
    "            \n",
    "        changes = []\n",
    "        #compare both dicts with sets of properties to check the differences\n",
    "        for key in prefix_properties_data.keys() & suffix_properties_data.keys():\n",
    "            for field in [\"label\", \"description\", \"dataType\", \"vocabulary\", \"metaData\"]:\n",
    "                value1 = prefix_properties_data[key][field]\n",
    "                value2 = suffix_properties_data[key][field]\n",
    "                if value1 != value2:\n",
    "                    if field == \"label\":\n",
    "                        changes.append(f\"Change in label of Property type {key}.\")\n",
    "                    elif field == \"description\":\n",
    "                        changes.append(f\"Change in description of Property type {key}.\")\n",
    "                    elif field == \"dataType\":\n",
    "                        changes.append(f\"Change in data type of Property type {key}.\")\n",
    "                    elif field == \"vocabulary\":\n",
    "                        changes.append(f\"Change in vocabulary code of Property type {key}.\")\n",
    "                    elif field == \"metaData\":\n",
    "                        changes.append(f\"Change in metadata of Property type {key}.\")\n",
    "\n",
    "        if (len(difference) != 0) or (len(changes) != 0):\n",
    "            errors.append(f\"As a specification of the entity type {prefix}, the entity type {entity_code} must include all Property types of {prefix} without any changes.\")\n",
    "            missing = \", \".join(difference)\n",
    "            if missing != \"\":\n",
    "                errors.append(f\"The missing properties are: \")\n",
    "                errors.append(missing)\n",
    "            else:\n",
    "                errors.append(f\"There are no missing properties\")\n",
    "            errors.append(f\"The changed property attributes are: \")\n",
    "            changed = \"\\n\".join(changes)\n",
    "            errors.append(changed)\n",
    "\n",
    "\n",
    "        # Recursively call the function with the prefix\n",
    "        check_prefix_prefix(o, prefix_2, entity_type, errors)\n",
    "        \n",
    "        \n",
    "def entity_checker(file_path):\n",
    "    errors = []\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    entity_type = sheet['A1'].value\n",
    "    entity_headers = [cell.value for cell in sheet[2]]\n",
    "    term_index = entity_headers.index(\"Code\") + 1\n",
    "    entity_code = sheet.cell(row=3, column=term_index).value\n",
    "    \n",
    "    try:\n",
    "        openbis_entity = search_entity(o, entity_type, entity_code)\n",
    "    except ValueError as e:\n",
    "        errors.append(f\"Entity type '{entity_code}' is a new entity type (not present in the system) to be registered.\")\n",
    "        openbis_entity = \"\"\n",
    "        \n",
    "    if (openbis_entity != \"\"):\n",
    "        errors.append(f\"Entity type '{entity_code}' already exists.\")\n",
    "        same_code_errors = check_entity_same_code(file_path, o, openbis_entity)\n",
    "        errors.append(same_code_errors)\n",
    "    else:\n",
    "        diff_code_errors = check_entity_diff_code(file_path, o)\n",
    "        errors.append(diff_code_errors)\n",
    "        \n",
    "    prefix_errors = check_prefix_sufix(file_path, o)\n",
    "    errors.append(prefix_errors)\n",
    "    \n",
    "    \n",
    "    return \"\\n\".join(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9868fe1-9f10-4b5f-9932-0532532e83fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_csv_and_download():\n",
    "    url = o.url\n",
    "    \n",
    "    header = [\"INSTANCE\", \"DATE\"]\n",
    "    \n",
    "    instance = url.split(\"//\")[1].split(\".\")[0]\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    info = [instance, current_date]\n",
    "\n",
    "    print(f\"Checking contents in instance: {instance}\\n\")\n",
    "    \n",
    "    # Fetch data from the server\n",
    "    spaces = []\n",
    "    projects = []\n",
    "    experiment_types = []\n",
    "    object_types = []\n",
    "    material_types = []\n",
    "    dataset_types = []\n",
    "    vocabs = []\n",
    "    plugins = []\n",
    "    \n",
    "    print(f\"Listing SPACES in {instance}\\n\")\n",
    "    print(f\"Total number of SPACES: {str(o.get_spaces().totalCount)}\\n\")\n",
    "\n",
    "    for space in o.get_spaces():\n",
    "        print(f\"  {space}\")\n",
    "        spaces.append(space)\n",
    "\n",
    "    print(f\"\\nListing PROJECTS in {instance}\\n\")\n",
    "    print(f\"Total number of PROJECTS: {str(o.get_projects().totalCount)}\\n\")\n",
    "\n",
    "    for project in o.get_projects():\n",
    "        print(f\"  {project.code}\")\n",
    "        projects.append(project.code)\n",
    "\n",
    "    print(f\"\\nListing EXPERIMENT TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of EXPERIMENT TYPES: {str(o.get_experiment_types().totalCount)}\\n\")\n",
    "    \n",
    "    for exp in o.get_experiment_types():\n",
    "        print(f\"  {exp}\")\n",
    "        experiment_types.append(exp)\n",
    "    \n",
    "    print(f\"\\nListing OBJECT TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of OBJECT TYPES: {str(o.get_object_types().totalCount)}\\n\")\n",
    "\n",
    "    objs = []\n",
    "    for obj in o.get_object_types():\n",
    "        objs.append(obj)\n",
    "        print(f\"  {obj}\")\n",
    "        if obj.code != \"UNKNOWN\":\n",
    "            object_types.append(obj)\n",
    "\n",
    "    print(f\"\\nListing MATERIAL TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of MATERIAL TYPES: {str(o.get_material_types().totalCount)}\\n\")\n",
    "    \n",
    "    for material in o.get_material_types():\n",
    "        print(f\"  {material}\")\n",
    "        material_types.append(material)\n",
    "    \n",
    "    print(f\"\\nListing DATASET TYPES in {instance}\\n\")\n",
    "    print(f\"Total number of DATASET TYPES: {str(o.get_dataset_types().totalCount)}\\n\")\n",
    "    \n",
    "    for dataset in o.get_dataset_types():\n",
    "        print(f\"  {dataset}\")\n",
    "        dataset_types.append(dataset)\n",
    "        \n",
    "    print(f\"\\nListing VOCABULARIES in {instance}\\n\")\n",
    "    print(f\"Total number of VOCABULARIES: {str(o.get_vocabularies().totalCount)}\\n\")\n",
    "    \n",
    "    for vocab in o.get_vocabularies():\n",
    "        print(f\"  {vocab.code}\")\n",
    "        vocabs.append(vocab.code)\n",
    "        \n",
    "    print(f\"\\nListing PLUGINS in {instance}\\n\")\n",
    "    print(f\"Total number of PLUGINS: {str(o.get_plugins().totalCount)}\\n\")\n",
    "    \n",
    "    for plug in o.get_plugins():\n",
    "        print(f\"  {plug.name}\")\n",
    "        plugins.append(plug.name)\n",
    "\n",
    "\n",
    "    masterdata_headers = [f\"SPACES ({len(spaces)})\", f\"PROJECTS ({len(projects)})\", f\"EXPERIMENT TYPES ({len(experiment_types)})\", \n",
    "                          f\"OBJECT TYPES ({len(object_types)})\", f\"DATASET TYPES ({len(dataset_types)})\",\n",
    "                          f\"VOCABULARIES ({len(vocabs)})\", f\"PLUGINS ({len(plugins)})\", f\"MATERIAL TYPES ({len(material_types)})\"]\n",
    "    \n",
    "    \n",
    "    # Combine master data into a list of lists\n",
    "    masterdata = [\n",
    "        spaces,\n",
    "        projects,\n",
    "        experiment_types,\n",
    "        object_types,\n",
    "        dataset_types,\n",
    "        vocabs,\n",
    "        plugins,\n",
    "        material_types\n",
    "    ]\n",
    "\n",
    "    # Directory name based on instance\n",
    "    directory = f\"{instance}_data\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # File path\n",
    "    filename = os.path.join(directory, f\"{instance}_{datetime.now().strftime('%d%m%Y')}.csv\")\n",
    "\n",
    "    \n",
    "    # Write data to CSV file\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the instance and date headers\n",
    "        writer.writerow([\"INSTANCE\", \"DATE\"])\n",
    "        \n",
    "        # Write the instance and date info\n",
    "        writer.writerow(info)\n",
    "        \n",
    "        # Write empty row\n",
    "        writer.writerow(\"\")\n",
    "        \n",
    "        # Write the master data headers\n",
    "        writer.writerow(masterdata_headers)\n",
    "        \n",
    "        # Determine the maximum length of the master data lists\n",
    "        max_length = max(len(data) for data in masterdata)\n",
    "        \n",
    "        # Write the master data vertically\n",
    "        for i in range(max_length):\n",
    "            row = []\n",
    "            for data in masterdata:\n",
    "                if i < len(data):\n",
    "                    row.append(data[i])\n",
    "                else:\n",
    "                    row.append(\"\")  # Append empty string if the list is shorter\n",
    "            writer.writerow(row)\n",
    "            \n",
    "        # Write empty row\n",
    "        writer.writerow(\"\")\n",
    "        \n",
    "        writer.writerow([\"PROPERTY LIST BY OBJECT TYPE\"])\n",
    "            \n",
    "        # Write another header row with the content of object_types horizontally\n",
    "        writer.writerow(object_types)\n",
    "        \n",
    "        props_by_obj = []\n",
    "        \n",
    "        for obj in object_types:\n",
    "            if obj.code == \"UNKNOWN\":\n",
    "                continue\n",
    "            print(f\"\\nPROPERTY LIST for OBJECT {obj.code}\\n\")\n",
    "            props = []\n",
    "            for prop in obj.get_property_assignments():\n",
    "                print(f\"{prop.code} --> {str(prop.dataType).lower()}\")\n",
    "                props.append(f\"{prop.code} ({str(prop.dataType).lower()})\")\n",
    "            props_by_obj.append(props)\n",
    "            \n",
    "        # Determine the maximum length of the object properties\n",
    "        max_length_props = max(len(properties) for properties in props_by_obj)\n",
    "        \n",
    "        # Write the master data vertically\n",
    "        for i in range(max_length_props):\n",
    "            row = []\n",
    "            for prop_list in props_by_obj:\n",
    "                if i < len(prop_list):\n",
    "                    row.append(prop_list[i])\n",
    "                else:\n",
    "                    row.append(\"\")  # Append empty string if the list is shorter\n",
    "            writer.writerow(row)\n",
    "        \n",
    "    return f\"\\nCSV file '{filename}' has been created.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c4b63-47cb-4ad9-a6ac-51b26e7b8696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fae730c9-eef4-423d-8292-66dfe969cb7d",
   "metadata": {},
   "source": [
    "## USE THE CHECKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491e890-9b78-405c-b85f-5aa3cee90b4a",
   "metadata": {},
   "source": [
    "Once executed all the function cells above, here we continue with the checker, where we will need to upload a file, and run the checker with that file against the selected instance in the beginning. If you just want to run the Masterdata Visualizer, you can ignore this part and go directly to the \"USE THE VISUALIZER\" cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59a4fb6-6be6-4c14-955a-df635a61cc9b",
   "metadata": {},
   "source": [
    "### UPLOAD THE EXCEL FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd6644-5e85-4a0c-afba-bfbf26e7fb52",
   "metadata": {},
   "source": [
    "Execute this cell below, and a button to upload a file will appear. Then, after clicking on the button, a window for selecting the desired file will appear. Once that you selected the file, you can continue to run the checker in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "024c26b0-64df-469e-88a0-fa3823dcab2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d686a3e082644f3a078f2ba07754161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.xlsx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploader = widgets.FileUpload(\n",
    "    accept='.xlsx',\n",
    "    multiple=False\n",
    ")\n",
    "\n",
    "def save_uploaded_file(uploader):\n",
    "    # Get the first uploaded file (since multiple=False, we expect only one file)\n",
    "    uploaded_file = uploader.value[0]\n",
    "    content = uploaded_file['content'].tobytes()\n",
    "    filename = uploaded_file['name']\n",
    "    \n",
    "    # Create a temporary file to save the uploaded content\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_file_path = os.path.join(temp_dir, filename)\n",
    "    \n",
    "    # Write the content to the temporary file\n",
    "    with open(temp_file_path, 'wb') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return temp_file_path\n",
    "\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e9f79-4230-4f99-989b-87ba39ec8446",
   "metadata": {},
   "source": [
    "### RUN THE CHECKER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f645e36-34d1-4859-bf35-186fc7644d05",
   "metadata": {},
   "source": [
    "Here just run the cell below, and the Masterdata Checker will start to run. A loading bar will appear with the different procesess, and once that it finishes, all the checks will appear below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64358cb4-73c0-4141-975d-afab8efd5dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ready to analyze\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8a5cf7350542378d55efd0d16dc683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Progress:   0%|          | 0/3 [00:00<?, ?task/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type: SAMPLE_TYPE\n",
      "\n",
      "NAME CHECKS:\n",
      "-------------\n",
      "File name: OK!\n",
      "\n",
      "CONTENT CHECKS:\n",
      "-------------\n",
      "Warning: It is recommended that the value of 'Generated code prefix' be the first three letters of each part of the 'Code' separated by dots ['.'].\n",
      "Error: Invalid value(s) found in the 'Description' column at row(s): 8, 9. Description should follow the schema: English Description + '//' + German Description.\n",
      "Error: Invalid value found in the 'Data type' column at row(s): 9. Accepted types: INTEGER, REAL, VARCHAR, MULTILINE_VARCHAR, HYPERLINK, BOOLEAN, CONTROLLEDVOCABULARY, XML, TIMESTAMP, DATE, SAMPLE\n",
      "\n",
      "ENTITY CHECKS\n",
      "-------------\n",
      "Entity type 'PYIRON_JOB' is a new entity type (not present in the system) to be registered.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if uploader.value:\n",
    "    file_path = save_uploaded_file(uploader)\n",
    "    print(f\"File ready to analyze\")\n",
    "else:\n",
    "    print(\"No file uploaded yet.\")\n",
    "\n",
    "file_name = file_path.split(\"\\\\\")[-1]\n",
    "\n",
    "# Initialize tqdm\n",
    "tasks = [\n",
    "    {\"name\": \"Name Check\", \"func\": name_checker, \"args\": (file_name,)},\n",
    "    {\"name\": \"Content Check\", \"func\": content_checker, \"args\": (file_path,)},\n",
    "    {\"name\": \"Entity Check\", \"func\": entity_checker, \"args\": (file_path,)}\n",
    "]\n",
    "\n",
    "with tqdm(total=len(tasks), desc=\"Overall Progress\", unit=\"task\") as pbar:\n",
    "    result_name = str(name_checker(file_name))\n",
    "    pbar.update(1)\n",
    "\n",
    "    if result_name != \"File name: OK!\":\n",
    "        result_format = \"\\nNAME CHECKS:\" + \"\\n-------------\\n\" + result_name\n",
    "    else:\n",
    "        result_content = str(content_checker(file_path))\n",
    "        pbar.update(1)\n",
    "        result_entity = str(entity_checker(file_path))\n",
    "        pbar.update(1)\n",
    "        result_format = \"\\nNAME CHECKS:\" + \"\\n-------------\\n\" + result_name + \"\\n\" + \"\\nCONTENT CHECKS:\" + \"\\n-------------\\n\" + result_content + \"\\n\" + \"\\nENTITY CHECKS\" + \"\\n-------------\\n\" + result_entity\n",
    "\n",
    "print(result_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392c880-8164-4af4-9960-b97503bd6b17",
   "metadata": {},
   "source": [
    "## USE THE VISUALIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f3fe3-1517-45fe-8fef-5069ee4050fa",
   "metadata": {},
   "source": [
    "Finally in this section we have the Masterdata Visualizer (which you can execute directly, without running the checker first). \n",
    "\n",
    "To run it, just execute the cell below, and it will generate a CSV file *in the same location* where this jupyter notebook is located (check your directory). \n",
    "\n",
    "More specifically, a folder with the name of the instance and data will appear (for example, \"main_data\" if you selected the main instance). Inside this folder, the different CSV files will be generated, once per day of execution (for example, executing it on the 30 of March 2024 in the main instance, the file inside the \"main_data\" folder will be called \"main_30032024.csv).\n",
    "\n",
    "Also, together with the CSV, we will have listed here all the information regarding the Masterdata content of the instance, if you just need a quick view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396423f5-53e6-4db2-b33a-b01c1c8c8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=100, desc=\"Generating CSV\", unit=\"percent\") as pbar:\n",
    "    for _ in range(10):\n",
    "        time.sleep(1)  # Simulate work being done in steps\n",
    "        pbar.update(10)\n",
    "\n",
    "    content = generate_csv_and_download()\n",
    "\n",
    "print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
